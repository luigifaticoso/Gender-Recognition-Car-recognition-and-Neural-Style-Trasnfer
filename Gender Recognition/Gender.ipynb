{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Gender.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "WH2QyuV6ltbE",
        "colab_type": "code",
        "outputId": "54309e55-5ef0-4e89-9756-1f6dfec9a1f8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%tensorflow_version 1.x"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gVWJ0hpJlx04",
        "colab_type": "code",
        "outputId": "6a4c8e8d-acb0-43a9-b4b4-c59386dd87bf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 598
        }
      },
      "source": [
        "!wget https://www.dropbox.com/s/zcwlujrtz3izcw8/gender.tgz\n",
        "!tar xvzf gender.tgz\n",
        "!ls"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-06-01 07:49:30--  https://www.dropbox.com/s/zcwlujrtz3izcw8/gender.tgz\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.81.1, 2620:100:6031:1::a27d:5101\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.81.1|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: /s/raw/zcwlujrtz3izcw8/gender.tgz [following]\n",
            "--2020-06-01 07:49:30--  https://www.dropbox.com/s/raw/zcwlujrtz3izcw8/gender.tgz\n",
            "Reusing existing connection to www.dropbox.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://uc04349d41cc0d166427849f54f7.dl.dropboxusercontent.com/cd/0/inline/A4ytNKuwFyCi0uBk52Z4MmbrnfMP7P7yqx3qO28XLUYp-uK6t63MaUy-lW0y6-De9HZEDDu8fru7xzW5i2HzK9jqywtF6t6rLDFxnoPvLQYqRA/file# [following]\n",
            "--2020-06-01 07:49:30--  https://uc04349d41cc0d166427849f54f7.dl.dropboxusercontent.com/cd/0/inline/A4ytNKuwFyCi0uBk52Z4MmbrnfMP7P7yqx3qO28XLUYp-uK6t63MaUy-lW0y6-De9HZEDDu8fru7xzW5i2HzK9jqywtF6t6rLDFxnoPvLQYqRA/file\n",
            "Resolving uc04349d41cc0d166427849f54f7.dl.dropboxusercontent.com (uc04349d41cc0d166427849f54f7.dl.dropboxusercontent.com)... 162.125.81.6, 2620:100:6031:6::a27d:5106\n",
            "Connecting to uc04349d41cc0d166427849f54f7.dl.dropboxusercontent.com (uc04349d41cc0d166427849f54f7.dl.dropboxusercontent.com)|162.125.81.6|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 FOUND\n",
            "Location: /cd/0/inline2/A4zDssicIq7X3jrDtvVhdnvvwQEy4FaTtS44EREtb48o3vOXCLM4xcs77gZPiCGzndeV6d-YuJ1OYDp1l_MTUL9NwZ7b0A-UeTRJp4uIYAi0d2MmeqxFAUhSNgvHmtcqDfj8uDo8-y4235omKZnTiEm3KPNqIu6LtqvPQRjqpVBlkN9Pji7qXz652SPnjDcgS-KncxNPNgBUotJOBF-vCpy02D4K9zZ7zeYnWuDFojsjZ6Ot3FKdoANYKX78ZiYcjvkjlcZoOczNsIa63dwvc4ornPGV3d_fDx2J-FkFgIdOVxEYeEIaXdFC5CHmg8FCCIakfNXHdszkRdFfpwSSPjQw/file [following]\n",
            "--2020-06-01 07:49:31--  https://uc04349d41cc0d166427849f54f7.dl.dropboxusercontent.com/cd/0/inline2/A4zDssicIq7X3jrDtvVhdnvvwQEy4FaTtS44EREtb48o3vOXCLM4xcs77gZPiCGzndeV6d-YuJ1OYDp1l_MTUL9NwZ7b0A-UeTRJp4uIYAi0d2MmeqxFAUhSNgvHmtcqDfj8uDo8-y4235omKZnTiEm3KPNqIu6LtqvPQRjqpVBlkN9Pji7qXz652SPnjDcgS-KncxNPNgBUotJOBF-vCpy02D4K9zZ7zeYnWuDFojsjZ6Ot3FKdoANYKX78ZiYcjvkjlcZoOczNsIa63dwvc4ornPGV3d_fDx2J-FkFgIdOVxEYeEIaXdFC5CHmg8FCCIakfNXHdszkRdFfpwSSPjQw/file\n",
            "Reusing existing connection to uc04349d41cc0d166427849f54f7.dl.dropboxusercontent.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 348494455 (332M) [application/x-gtar]\n",
            "Saving to: ‘gender.tgz’\n",
            "\n",
            "gender.tgz          100%[===================>] 332.35M  39.8MB/s    in 8.2s    \n",
            "\n",
            "2020-06-01 07:49:40 (40.8 MB/s) - ‘gender.tgz’ saved [348494455/348494455]\n",
            "\n",
            "./._x_test.npy\n",
            "x_test.npy\n",
            "./._x_train.npy\n",
            "x_train.npy\n",
            "./._y_test.npy\n",
            "y_test.npy\n",
            "./._y_train.npy\n",
            "y_train.npy\n",
            "gender.tgz  sample_data  x_test.npy  x_train.npy  y_test.npy  y_train.npy\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CLTi9_HDlz2q",
        "colab_type": "code",
        "outputId": "86afd553-35f0-41d4-8546-475ec023960a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from __future__ import print_function\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import keras\n",
        "from keras import layers\n",
        "from keras.datasets import cifar10\n",
        "from keras import models\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.layers.normalization import BatchNormalization as BN\n",
        "from keras.layers import GaussianNoise as GN\n",
        "from keras.optimizers import SGD\n",
        "from keras.callbacks import ReduceLROnPlateau\n",
        "from keras.callbacks import LearningRateScheduler as LRS\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.backend.tensorflow_backend import set_session\n",
        "import tensorflow as tf\n",
        "config = tf.ConfigProto()\n",
        "config.gpu_options.allow_growth=True\n",
        "\n",
        "# con tensorflow:\n",
        "with tf.Session(config=config):\n",
        "    # con keras:\n",
        "    set_session(tf.Session(config=config))\n",
        "    \n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cCEOUElBl-zg",
        "colab_type": "code",
        "outputId": "357fa9d6-a942-4550-f955-6f2e66a8986f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "    \n",
        "# Load \n",
        "x_train = np.load('x_train.npy')\n",
        "x_test = np.load('x_test.npy')\n",
        "\n",
        "y_train = np.load('y_train.npy')\n",
        "y_test = np.load('y_test.npy')\n",
        "\n",
        "\n",
        "## Transforms\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "\n",
        "y_train = y_train.astype('float32')\n",
        "y_test = y_test.astype('float32')\n",
        "\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "\n",
        "print(x_train.shape)\n",
        "print(x_test.shape)\n",
        "\n",
        "num_classes = 2\n",
        "\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
        "\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(10585, 100, 100, 3)\n",
            "(2648, 100, 100, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4FKdG8tYmC1E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "## DEFINE A DATA AUGMENTATION GENERATOR\n",
        "\n",
        "datagen = ImageDataGenerator(\n",
        "  width_shift_range=0.2,\n",
        "  height_shift_range=0.2,\n",
        "  rotation_range=20,\n",
        "  zoom_range=[1.0,1.2],\n",
        "  horizontal_flip=True)\n",
        "\n",
        "###########################################################\n",
        "# Now this is necessary due to the feature normalization: #\n",
        "datagen.fit(x_train)\n",
        "###########################################################\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LH2vkViEmH2h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "## Resnet\n",
        "def convo_block(y, filtros, num_conv, res=0):\n",
        "\n",
        "    if (res):\n",
        "        x=y\n",
        "\n",
        "    s = 2\n",
        "    for i in range(num_conv):\n",
        "        \n",
        "        y=layers.Conv2D(filtros, kernel_size=(3, 3), strides=(s,s), padding='same')(y)\n",
        "        s = 1\n",
        "        y=layers.BatchNormalization()(y)\n",
        "        y=layers.GaussianNoise(0.3)(y)\n",
        "        \n",
        "        if (i<num_conv-1):\n",
        "            y=layers.ReLU()(y)\n",
        "\n",
        "\n",
        "    if (res):\n",
        "        \n",
        "        x=layers.Conv2D(filtros, kernel_size=(1, 1), strides=(2,2),padding='same')(x)\n",
        "        y=layers.add([x, y])\n",
        "        y=layers.ReLU()(y)\n",
        "\n",
        "    else:\n",
        "        y=layers.MaxPooling2D(pool_size=(2, 2))(y)\n",
        "        \n",
        "    return y\n",
        "\n",
        "\n",
        "def generate_model( num_conv_blocks):\n",
        "  \n",
        "    filtros = 32\n",
        "    n_conv = 2\n",
        "    input_layer = layers.Input(shape=(100,100,3))\n",
        "    x = convo_block(input_layer, filtros, n_conv)\n",
        "    #Convolutional part\n",
        "    for i in range(num_conv_blocks-1):\n",
        "      x = convo_block(x, filtros, n_conv, res=1)\n",
        "      filtros = filtros * 2\n",
        "\n",
        "    x=layers.Flatten()(x)\n",
        "    x=layers.Dense(512)(x)\n",
        "    x=layers.BatchNormalization()(x)\n",
        "    x=layers.GaussianNoise(0.3)(x)\n",
        "    x=layers.ReLU()(x)\n",
        "\n",
        "    x=layers.Dense(2, activation='softmax')(x)\n",
        "    model = models.Model(inputs=[input_layer], outputs=[x])\n",
        "\n",
        "    return model\n",
        " "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wf9uk-l-mOsB",
        "colab_type": "code",
        "outputId": "158c664d-5402-4d55-8131-764c35781911",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "    \n",
        "model = generate_model(4)\n",
        "model.summary()\n",
        "\n",
        "## OPTIM AND COMPILE\n",
        "opt = SGD(lr=0.1, decay=1e-6)\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=opt,\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# DEFINE A LEARNING RATE SCHEDULER\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, cooldown=1,\n",
        "                              patience=10, min_lr=0.005)\n",
        "\n",
        "## TRAINING with DA and LRA\n",
        "\n",
        "batch_size = 100\n",
        "epochs = 300\n",
        "\n",
        "history=model.fit_generator(datagen.flow(x_train, y_train,batch_size=batch_size),\n",
        "                            steps_per_epoch=len(x_train) / batch_size, \n",
        "                            epochs=epochs,\n",
        "                            validation_data=(x_test, y_test),\n",
        "                            callbacks=[reduce_lr],\n",
        "                            verbose=1)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, 100, 100, 3)  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 50, 50, 32)   896         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 50, 50, 32)   128         conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "gaussian_noise_1 (GaussianNoise (None, 50, 50, 32)   0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_1 (ReLU)                  (None, 50, 50, 32)   0           gaussian_noise_1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 50, 50, 32)   9248        re_lu_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 50, 50, 32)   128         conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "gaussian_noise_2 (GaussianNoise (None, 50, 50, 32)   0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 25, 25, 32)   0           gaussian_noise_2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 13, 13, 32)   9248        max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 13, 13, 32)   128         conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "gaussian_noise_3 (GaussianNoise (None, 13, 13, 32)   0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_2 (ReLU)                  (None, 13, 13, 32)   0           gaussian_noise_3[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 13, 13, 32)   9248        re_lu_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 13, 13, 32)   128         conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 13, 13, 32)   1056        max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "gaussian_noise_4 (GaussianNoise (None, 13, 13, 32)   0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "add_1 (Add)                     (None, 13, 13, 32)   0           conv2d_5[0][0]                   \n",
            "                                                                 gaussian_noise_4[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_3 (ReLU)                  (None, 13, 13, 32)   0           add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 7, 7, 64)     18496       re_lu_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 7, 7, 64)     256         conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "gaussian_noise_5 (GaussianNoise (None, 7, 7, 64)     0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_4 (ReLU)                  (None, 7, 7, 64)     0           gaussian_noise_5[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 7, 7, 64)     36928       re_lu_4[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 7, 7, 64)     256         conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 7, 7, 64)     2112        re_lu_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "gaussian_noise_6 (GaussianNoise (None, 7, 7, 64)     0           batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "add_2 (Add)                     (None, 7, 7, 64)     0           conv2d_8[0][0]                   \n",
            "                                                                 gaussian_noise_6[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_5 (ReLU)                  (None, 7, 7, 64)     0           add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 4, 4, 128)    73856       re_lu_5[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 4, 4, 128)    512         conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "gaussian_noise_7 (GaussianNoise (None, 4, 4, 128)    0           batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_6 (ReLU)                  (None, 4, 4, 128)    0           gaussian_noise_7[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 4, 4, 128)    147584      re_lu_6[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 4, 4, 128)    512         conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 4, 4, 128)    8320        re_lu_5[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "gaussian_noise_8 (GaussianNoise (None, 4, 4, 128)    0           batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "add_3 (Add)                     (None, 4, 4, 128)    0           conv2d_11[0][0]                  \n",
            "                                                                 gaussian_noise_8[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_7 (ReLU)                  (None, 4, 4, 128)    0           add_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "flatten_1 (Flatten)             (None, 2048)         0           re_lu_7[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 512)          1049088     flatten_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 512)          2048        dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "gaussian_noise_9 (GaussianNoise (None, 512)          0           batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_8 (ReLU)                  (None, 512)          0           gaussian_noise_9[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 2)            1026        re_lu_8[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 1,371,202\n",
            "Trainable params: 1,369,154\n",
            "Non-trainable params: 2,048\n",
            "__________________________________________________________________________________________________\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "Epoch 1/300\n",
            "106/105 [==============================] - 32s 302ms/step - loss: 0.6017 - accuracy: 0.7483 - val_loss: 0.7333 - val_accuracy: 0.3176\n",
            "Epoch 2/300\n",
            "106/105 [==============================] - 24s 230ms/step - loss: 0.4475 - accuracy: 0.7994 - val_loss: 0.6158 - val_accuracy: 0.6662\n",
            "Epoch 3/300\n",
            "106/105 [==============================] - 25s 231ms/step - loss: 0.4091 - accuracy: 0.8163 - val_loss: 0.3785 - val_accuracy: 0.8304\n",
            "Epoch 4/300\n",
            "106/105 [==============================] - 25s 233ms/step - loss: 0.3761 - accuracy: 0.8329 - val_loss: 0.5668 - val_accuracy: 0.6990\n",
            "Epoch 5/300\n",
            "106/105 [==============================] - 24s 229ms/step - loss: 0.3764 - accuracy: 0.8323 - val_loss: 0.3611 - val_accuracy: 0.8308\n",
            "Epoch 6/300\n",
            "106/105 [==============================] - 25s 232ms/step - loss: 0.3466 - accuracy: 0.8453 - val_loss: 0.3549 - val_accuracy: 0.8557\n",
            "Epoch 7/300\n",
            "106/105 [==============================] - 24s 230ms/step - loss: 0.3463 - accuracy: 0.8468 - val_loss: 0.3118 - val_accuracy: 0.8535\n",
            "Epoch 8/300\n",
            "106/105 [==============================] - 24s 227ms/step - loss: 0.3307 - accuracy: 0.8570 - val_loss: 0.3286 - val_accuracy: 0.8497\n",
            "Epoch 9/300\n",
            "106/105 [==============================] - 24s 228ms/step - loss: 0.3185 - accuracy: 0.8613 - val_loss: 0.5156 - val_accuracy: 0.7489\n",
            "Epoch 10/300\n",
            "106/105 [==============================] - 24s 226ms/step - loss: 0.3070 - accuracy: 0.8652 - val_loss: 0.4083 - val_accuracy: 0.8059\n",
            "Epoch 11/300\n",
            "106/105 [==============================] - 24s 227ms/step - loss: 0.2939 - accuracy: 0.8744 - val_loss: 0.5279 - val_accuracy: 0.7262\n",
            "Epoch 12/300\n",
            "106/105 [==============================] - 24s 226ms/step - loss: 0.2823 - accuracy: 0.8791 - val_loss: 0.3050 - val_accuracy: 0.8780\n",
            "Epoch 13/300\n",
            "106/105 [==============================] - 24s 225ms/step - loss: 0.2762 - accuracy: 0.8838 - val_loss: 0.2472 - val_accuracy: 0.8909\n",
            "Epoch 14/300\n",
            "106/105 [==============================] - 24s 225ms/step - loss: 0.2706 - accuracy: 0.8855 - val_loss: 0.2714 - val_accuracy: 0.8776\n",
            "Epoch 15/300\n",
            "106/105 [==============================] - 23s 220ms/step - loss: 0.2552 - accuracy: 0.8930 - val_loss: 0.2275 - val_accuracy: 0.9045\n",
            "Epoch 16/300\n",
            "106/105 [==============================] - 23s 221ms/step - loss: 0.2567 - accuracy: 0.8942 - val_loss: 0.2155 - val_accuracy: 0.9082\n",
            "Epoch 17/300\n",
            "106/105 [==============================] - 23s 220ms/step - loss: 0.2436 - accuracy: 0.8983 - val_loss: 0.3228 - val_accuracy: 0.8437\n",
            "Epoch 18/300\n",
            "106/105 [==============================] - 23s 221ms/step - loss: 0.2292 - accuracy: 0.9089 - val_loss: 0.2335 - val_accuracy: 0.8958\n",
            "Epoch 19/300\n",
            "106/105 [==============================] - 23s 221ms/step - loss: 0.2257 - accuracy: 0.9084 - val_loss: 0.2020 - val_accuracy: 0.9147\n",
            "Epoch 20/300\n",
            "106/105 [==============================] - 24s 225ms/step - loss: 0.2144 - accuracy: 0.9132 - val_loss: 0.2318 - val_accuracy: 0.9041\n",
            "Epoch 21/300\n",
            "106/105 [==============================] - 24s 224ms/step - loss: 0.2068 - accuracy: 0.9158 - val_loss: 0.2531 - val_accuracy: 0.9041\n",
            "Epoch 22/300\n",
            "106/105 [==============================] - 24s 223ms/step - loss: 0.2032 - accuracy: 0.9156 - val_loss: 0.2694 - val_accuracy: 0.8818\n",
            "Epoch 23/300\n",
            "106/105 [==============================] - 24s 223ms/step - loss: 0.2001 - accuracy: 0.9184 - val_loss: 0.1811 - val_accuracy: 0.9267\n",
            "Epoch 24/300\n",
            "106/105 [==============================] - 24s 225ms/step - loss: 0.1964 - accuracy: 0.9209 - val_loss: 0.4341 - val_accuracy: 0.7991\n",
            "Epoch 25/300\n",
            "106/105 [==============================] - 24s 224ms/step - loss: 0.1890 - accuracy: 0.9228 - val_loss: 0.2180 - val_accuracy: 0.9037\n",
            "Epoch 26/300\n",
            "106/105 [==============================] - 24s 224ms/step - loss: 0.1817 - accuracy: 0.9277 - val_loss: 0.3123 - val_accuracy: 0.8576\n",
            "Epoch 27/300\n",
            "106/105 [==============================] - 24s 222ms/step - loss: 0.1822 - accuracy: 0.9280 - val_loss: 0.2277 - val_accuracy: 0.9071\n",
            "Epoch 28/300\n",
            "106/105 [==============================] - 24s 224ms/step - loss: 0.1759 - accuracy: 0.9313 - val_loss: 0.1756 - val_accuracy: 0.9301\n",
            "Epoch 29/300\n",
            "106/105 [==============================] - 24s 225ms/step - loss: 0.1689 - accuracy: 0.9304 - val_loss: 0.1348 - val_accuracy: 0.9475\n",
            "Epoch 30/300\n",
            "106/105 [==============================] - 24s 225ms/step - loss: 0.1676 - accuracy: 0.9325 - val_loss: 0.2141 - val_accuracy: 0.9139\n",
            "Epoch 31/300\n",
            "106/105 [==============================] - 24s 226ms/step - loss: 0.1733 - accuracy: 0.9317 - val_loss: 0.1720 - val_accuracy: 0.9286\n",
            "Epoch 32/300\n",
            "106/105 [==============================] - 24s 226ms/step - loss: 0.1628 - accuracy: 0.9333 - val_loss: 0.1180 - val_accuracy: 0.9577\n",
            "Epoch 33/300\n",
            "106/105 [==============================] - 24s 227ms/step - loss: 0.1582 - accuracy: 0.9353 - val_loss: 0.1725 - val_accuracy: 0.9264\n",
            "Epoch 34/300\n",
            "106/105 [==============================] - 24s 225ms/step - loss: 0.1535 - accuracy: 0.9400 - val_loss: 0.1795 - val_accuracy: 0.9237\n",
            "Epoch 35/300\n",
            "106/105 [==============================] - 24s 225ms/step - loss: 0.1518 - accuracy: 0.9431 - val_loss: 0.1728 - val_accuracy: 0.9328\n",
            "Epoch 36/300\n",
            "106/105 [==============================] - 24s 224ms/step - loss: 0.1501 - accuracy: 0.9401 - val_loss: 0.1284 - val_accuracy: 0.9502\n",
            "Epoch 37/300\n",
            "106/105 [==============================] - 24s 224ms/step - loss: 0.1527 - accuracy: 0.9392 - val_loss: 0.1658 - val_accuracy: 0.9358\n",
            "Epoch 38/300\n",
            "106/105 [==============================] - 24s 227ms/step - loss: 0.1500 - accuracy: 0.9410 - val_loss: 0.1514 - val_accuracy: 0.9407\n",
            "Epoch 39/300\n",
            "106/105 [==============================] - 24s 224ms/step - loss: 0.1454 - accuracy: 0.9416 - val_loss: 0.1766 - val_accuracy: 0.9260\n",
            "Epoch 40/300\n",
            "106/105 [==============================] - 24s 223ms/step - loss: 0.1443 - accuracy: 0.9436 - val_loss: 0.1250 - val_accuracy: 0.9539\n",
            "Epoch 41/300\n",
            "106/105 [==============================] - 24s 224ms/step - loss: 0.1438 - accuracy: 0.9414 - val_loss: 0.1765 - val_accuracy: 0.9381\n",
            "Epoch 42/300\n",
            "106/105 [==============================] - 24s 224ms/step - loss: 0.1363 - accuracy: 0.9464 - val_loss: 0.2004 - val_accuracy: 0.9067\n",
            "Epoch 43/300\n",
            "106/105 [==============================] - 24s 222ms/step - loss: 0.1331 - accuracy: 0.9476 - val_loss: 0.1149 - val_accuracy: 0.9596\n",
            "Epoch 44/300\n",
            "106/105 [==============================] - 24s 222ms/step - loss: 0.1274 - accuracy: 0.9495 - val_loss: 0.1662 - val_accuracy: 0.9275\n",
            "Epoch 45/300\n",
            "106/105 [==============================] - 24s 223ms/step - loss: 0.1236 - accuracy: 0.9514 - val_loss: 0.2009 - val_accuracy: 0.9139\n",
            "Epoch 46/300\n",
            "106/105 [==============================] - 24s 224ms/step - loss: 0.1185 - accuracy: 0.9515 - val_loss: 0.0998 - val_accuracy: 0.9649\n",
            "Epoch 47/300\n",
            "106/105 [==============================] - 23s 221ms/step - loss: 0.1190 - accuracy: 0.9518 - val_loss: 0.1050 - val_accuracy: 0.9596\n",
            "Epoch 48/300\n",
            "106/105 [==============================] - 24s 223ms/step - loss: 0.1252 - accuracy: 0.9507 - val_loss: 0.1461 - val_accuracy: 0.9366\n",
            "Epoch 49/300\n",
            "106/105 [==============================] - 23s 221ms/step - loss: 0.1183 - accuracy: 0.9556 - val_loss: 0.0991 - val_accuracy: 0.9634\n",
            "Epoch 50/300\n",
            "106/105 [==============================] - 24s 222ms/step - loss: 0.1203 - accuracy: 0.9554 - val_loss: 0.1078 - val_accuracy: 0.9581\n",
            "Epoch 51/300\n",
            "106/105 [==============================] - 24s 224ms/step - loss: 0.1167 - accuracy: 0.9561 - val_loss: 0.1083 - val_accuracy: 0.9577\n",
            "Epoch 52/300\n",
            "106/105 [==============================] - 24s 222ms/step - loss: 0.1228 - accuracy: 0.9532 - val_loss: 0.1069 - val_accuracy: 0.9615\n",
            "Epoch 53/300\n",
            "106/105 [==============================] - 24s 222ms/step - loss: 0.1183 - accuracy: 0.9526 - val_loss: 0.1182 - val_accuracy: 0.9543\n",
            "Epoch 54/300\n",
            "106/105 [==============================] - 23s 220ms/step - loss: 0.1141 - accuracy: 0.9580 - val_loss: 0.1040 - val_accuracy: 0.9588\n",
            "Epoch 55/300\n",
            "106/105 [==============================] - 23s 221ms/step - loss: 0.1133 - accuracy: 0.9565 - val_loss: 0.1090 - val_accuracy: 0.9603\n",
            "Epoch 56/300\n",
            "106/105 [==============================] - 23s 219ms/step - loss: 0.1152 - accuracy: 0.9563 - val_loss: 0.0981 - val_accuracy: 0.9603\n",
            "Epoch 57/300\n",
            "106/105 [==============================] - 23s 220ms/step - loss: 0.1116 - accuracy: 0.9555 - val_loss: 0.2274 - val_accuracy: 0.8939\n",
            "Epoch 58/300\n",
            "106/105 [==============================] - 23s 221ms/step - loss: 0.1136 - accuracy: 0.9576 - val_loss: 0.1120 - val_accuracy: 0.9585\n",
            "Epoch 59/300\n",
            "106/105 [==============================] - 23s 221ms/step - loss: 0.1147 - accuracy: 0.9550 - val_loss: 0.1167 - val_accuracy: 0.9517\n",
            "Epoch 60/300\n",
            "106/105 [==============================] - 23s 220ms/step - loss: 0.1166 - accuracy: 0.9549 - val_loss: 0.1277 - val_accuracy: 0.9464\n",
            "Epoch 61/300\n",
            "106/105 [==============================] - 23s 221ms/step - loss: 0.1149 - accuracy: 0.9555 - val_loss: 0.1198 - val_accuracy: 0.9490\n",
            "Epoch 62/300\n",
            "106/105 [==============================] - 23s 221ms/step - loss: 0.1073 - accuracy: 0.9583 - val_loss: 0.1483 - val_accuracy: 0.9343\n",
            "Epoch 63/300\n",
            "106/105 [==============================] - 23s 219ms/step - loss: 0.1133 - accuracy: 0.9554 - val_loss: 0.0976 - val_accuracy: 0.9645\n",
            "Epoch 64/300\n",
            "106/105 [==============================] - 23s 220ms/step - loss: 0.1092 - accuracy: 0.9550 - val_loss: 0.0896 - val_accuracy: 0.9653\n",
            "Epoch 65/300\n",
            "106/105 [==============================] - 24s 222ms/step - loss: 0.1105 - accuracy: 0.9571 - val_loss: 0.0903 - val_accuracy: 0.9675\n",
            "Epoch 66/300\n",
            "106/105 [==============================] - 23s 220ms/step - loss: 0.1089 - accuracy: 0.9556 - val_loss: 0.1382 - val_accuracy: 0.9407\n",
            "Epoch 67/300\n",
            "106/105 [==============================] - 23s 219ms/step - loss: 0.1064 - accuracy: 0.9590 - val_loss: 0.1624 - val_accuracy: 0.9279\n",
            "Epoch 68/300\n",
            "106/105 [==============================] - 23s 218ms/step - loss: 0.1090 - accuracy: 0.9588 - val_loss: 0.1098 - val_accuracy: 0.9551\n",
            "Epoch 69/300\n",
            "106/105 [==============================] - 23s 217ms/step - loss: 0.1124 - accuracy: 0.9575 - val_loss: 0.0916 - val_accuracy: 0.9683\n",
            "Epoch 70/300\n",
            "106/105 [==============================] - 23s 217ms/step - loss: 0.1061 - accuracy: 0.9607 - val_loss: 0.0918 - val_accuracy: 0.9668\n",
            "Epoch 71/300\n",
            "106/105 [==============================] - 23s 216ms/step - loss: 0.1038 - accuracy: 0.9586 - val_loss: 0.1103 - val_accuracy: 0.9585\n",
            "Epoch 72/300\n",
            "106/105 [==============================] - 23s 220ms/step - loss: 0.1038 - accuracy: 0.9600 - val_loss: 0.1427 - val_accuracy: 0.9445\n",
            "Epoch 73/300\n",
            "106/105 [==============================] - 23s 218ms/step - loss: 0.1049 - accuracy: 0.9589 - val_loss: 0.1436 - val_accuracy: 0.9415\n",
            "Epoch 74/300\n",
            "106/105 [==============================] - 23s 218ms/step - loss: 0.1074 - accuracy: 0.9579 - val_loss: 0.1819 - val_accuracy: 0.9147\n",
            "Epoch 75/300\n",
            "106/105 [==============================] - 23s 220ms/step - loss: 0.1009 - accuracy: 0.9628 - val_loss: 0.0927 - val_accuracy: 0.9645\n",
            "Epoch 76/300\n",
            "106/105 [==============================] - 23s 219ms/step - loss: 0.0951 - accuracy: 0.9646 - val_loss: 0.1339 - val_accuracy: 0.9437\n",
            "Epoch 77/300\n",
            "106/105 [==============================] - 23s 219ms/step - loss: 0.0968 - accuracy: 0.9613 - val_loss: 0.1267 - val_accuracy: 0.9475\n",
            "Epoch 78/300\n",
            "106/105 [==============================] - 23s 218ms/step - loss: 0.1007 - accuracy: 0.9611 - val_loss: 0.0952 - val_accuracy: 0.9637\n",
            "Epoch 79/300\n",
            "106/105 [==============================] - 23s 219ms/step - loss: 0.0938 - accuracy: 0.9633 - val_loss: 0.1211 - val_accuracy: 0.9520\n",
            "Epoch 80/300\n",
            "106/105 [==============================] - 23s 218ms/step - loss: 0.0905 - accuracy: 0.9663 - val_loss: 0.1134 - val_accuracy: 0.9573\n",
            "Epoch 81/300\n",
            "106/105 [==============================] - 23s 218ms/step - loss: 0.0987 - accuracy: 0.9619 - val_loss: 0.1128 - val_accuracy: 0.9554\n",
            "Epoch 82/300\n",
            "106/105 [==============================] - 23s 219ms/step - loss: 0.0972 - accuracy: 0.9617 - val_loss: 0.1050 - val_accuracy: 0.9600\n",
            "Epoch 83/300\n",
            "106/105 [==============================] - 23s 218ms/step - loss: 0.0971 - accuracy: 0.9636 - val_loss: 0.1094 - val_accuracy: 0.9577\n",
            "Epoch 84/300\n",
            "106/105 [==============================] - 23s 218ms/step - loss: 0.0923 - accuracy: 0.9661 - val_loss: 0.0999 - val_accuracy: 0.9656\n",
            "Epoch 85/300\n",
            "106/105 [==============================] - 23s 218ms/step - loss: 0.0943 - accuracy: 0.9634 - val_loss: 0.1161 - val_accuracy: 0.9539\n",
            "Epoch 86/300\n",
            "106/105 [==============================] - 23s 219ms/step - loss: 0.0874 - accuracy: 0.9653 - val_loss: 0.1047 - val_accuracy: 0.9592\n",
            "Epoch 87/300\n",
            "106/105 [==============================] - 23s 216ms/step - loss: 0.0914 - accuracy: 0.9665 - val_loss: 0.1112 - val_accuracy: 0.9566\n",
            "Epoch 88/300\n",
            "106/105 [==============================] - 23s 218ms/step - loss: 0.0913 - accuracy: 0.9634 - val_loss: 0.1085 - val_accuracy: 0.9596\n",
            "Epoch 89/300\n",
            "106/105 [==============================] - 23s 219ms/step - loss: 0.0867 - accuracy: 0.9650 - val_loss: 0.0975 - val_accuracy: 0.9641\n",
            "Epoch 90/300\n",
            "106/105 [==============================] - 23s 220ms/step - loss: 0.0944 - accuracy: 0.9625 - val_loss: 0.1505 - val_accuracy: 0.9366\n",
            "Epoch 91/300\n",
            "106/105 [==============================] - 23s 219ms/step - loss: 0.0868 - accuracy: 0.9658 - val_loss: 0.0915 - val_accuracy: 0.9671\n",
            "Epoch 92/300\n",
            "106/105 [==============================] - 23s 217ms/step - loss: 0.0902 - accuracy: 0.9653 - val_loss: 0.0970 - val_accuracy: 0.9630\n",
            "Epoch 93/300\n",
            "106/105 [==============================] - 23s 218ms/step - loss: 0.0915 - accuracy: 0.9647 - val_loss: 0.1159 - val_accuracy: 0.9573\n",
            "Epoch 94/300\n",
            "106/105 [==============================] - 23s 215ms/step - loss: 0.0884 - accuracy: 0.9650 - val_loss: 0.1131 - val_accuracy: 0.9562\n",
            "Epoch 95/300\n",
            "106/105 [==============================] - 23s 217ms/step - loss: 0.0861 - accuracy: 0.9673 - val_loss: 0.1146 - val_accuracy: 0.9547\n",
            "Epoch 96/300\n",
            "106/105 [==============================] - 23s 218ms/step - loss: 0.0903 - accuracy: 0.9653 - val_loss: 0.1012 - val_accuracy: 0.9626\n",
            "Epoch 97/300\n",
            "106/105 [==============================] - 23s 218ms/step - loss: 0.0892 - accuracy: 0.9662 - val_loss: 0.1103 - val_accuracy: 0.9554\n",
            "Epoch 98/300\n",
            "106/105 [==============================] - 23s 219ms/step - loss: 0.0909 - accuracy: 0.9653 - val_loss: 0.0987 - val_accuracy: 0.9626\n",
            "Epoch 99/300\n",
            "106/105 [==============================] - 23s 219ms/step - loss: 0.0904 - accuracy: 0.9653 - val_loss: 0.0953 - val_accuracy: 0.9637\n",
            "Epoch 100/300\n",
            "106/105 [==============================] - 23s 220ms/step - loss: 0.0889 - accuracy: 0.9674 - val_loss: 0.1091 - val_accuracy: 0.9569\n",
            "Epoch 101/300\n",
            "106/105 [==============================] - 23s 218ms/step - loss: 0.0881 - accuracy: 0.9656 - val_loss: 0.1345 - val_accuracy: 0.9471\n",
            "Epoch 102/300\n",
            "106/105 [==============================] - 23s 218ms/step - loss: 0.0926 - accuracy: 0.9630 - val_loss: 0.0980 - val_accuracy: 0.9637\n",
            "Epoch 103/300\n",
            "106/105 [==============================] - 23s 219ms/step - loss: 0.0923 - accuracy: 0.9645 - val_loss: 0.1045 - val_accuracy: 0.9588\n",
            "Epoch 104/300\n",
            "106/105 [==============================] - 23s 219ms/step - loss: 0.0905 - accuracy: 0.9659 - val_loss: 0.1134 - val_accuracy: 0.9558\n",
            "Epoch 105/300\n",
            "106/105 [==============================] - 23s 218ms/step - loss: 0.0817 - accuracy: 0.9686 - val_loss: 0.1057 - val_accuracy: 0.9588\n",
            "Epoch 106/300\n",
            "106/105 [==============================] - 23s 219ms/step - loss: 0.0883 - accuracy: 0.9642 - val_loss: 0.1173 - val_accuracy: 0.9532\n",
            "Epoch 107/300\n",
            "106/105 [==============================] - 23s 220ms/step - loss: 0.0875 - accuracy: 0.9655 - val_loss: 0.1044 - val_accuracy: 0.9581\n",
            "Epoch 108/300\n",
            "106/105 [==============================] - 23s 219ms/step - loss: 0.0903 - accuracy: 0.9638 - val_loss: 0.1057 - val_accuracy: 0.9569\n",
            "Epoch 109/300\n",
            "106/105 [==============================] - 23s 218ms/step - loss: 0.0858 - accuracy: 0.9667 - val_loss: 0.1075 - val_accuracy: 0.9581\n",
            "Epoch 110/300\n",
            "106/105 [==============================] - 24s 222ms/step - loss: 0.0862 - accuracy: 0.9667 - val_loss: 0.1130 - val_accuracy: 0.9554\n",
            "Epoch 111/300\n",
            "106/105 [==============================] - 23s 220ms/step - loss: 0.0805 - accuracy: 0.9687 - val_loss: 0.1044 - val_accuracy: 0.9600\n",
            "Epoch 112/300\n",
            "106/105 [==============================] - 24s 223ms/step - loss: 0.0837 - accuracy: 0.9662 - val_loss: 0.1049 - val_accuracy: 0.9592\n",
            "Epoch 113/300\n",
            "106/105 [==============================] - 23s 221ms/step - loss: 0.0833 - accuracy: 0.9686 - val_loss: 0.1115 - val_accuracy: 0.9558\n",
            "Epoch 114/300\n",
            "106/105 [==============================] - 24s 224ms/step - loss: 0.0869 - accuracy: 0.9671 - val_loss: 0.1151 - val_accuracy: 0.9551\n",
            "Epoch 115/300\n",
            "106/105 [==============================] - 24s 222ms/step - loss: 0.0852 - accuracy: 0.9668 - val_loss: 0.1169 - val_accuracy: 0.9543\n",
            "Epoch 116/300\n",
            "106/105 [==============================] - 24s 223ms/step - loss: 0.0896 - accuracy: 0.9650 - val_loss: 0.1151 - val_accuracy: 0.9543\n",
            "Epoch 117/300\n",
            "106/105 [==============================] - 24s 223ms/step - loss: 0.0839 - accuracy: 0.9691 - val_loss: 0.1027 - val_accuracy: 0.9588\n",
            "Epoch 118/300\n",
            "106/105 [==============================] - 23s 218ms/step - loss: 0.0872 - accuracy: 0.9672 - val_loss: 0.1149 - val_accuracy: 0.9535\n",
            "Epoch 119/300\n",
            "106/105 [==============================] - 23s 219ms/step - loss: 0.0838 - accuracy: 0.9675 - val_loss: 0.1085 - val_accuracy: 0.9569\n",
            "Epoch 120/300\n",
            "106/105 [==============================] - 23s 221ms/step - loss: 0.0843 - accuracy: 0.9665 - val_loss: 0.1226 - val_accuracy: 0.9505\n",
            "Epoch 121/300\n",
            "106/105 [==============================] - 23s 221ms/step - loss: 0.0851 - accuracy: 0.9682 - val_loss: 0.1162 - val_accuracy: 0.9551\n",
            "Epoch 122/300\n",
            "106/105 [==============================] - 23s 219ms/step - loss: 0.0853 - accuracy: 0.9676 - val_loss: 0.1396 - val_accuracy: 0.9407\n",
            "Epoch 123/300\n",
            "106/105 [==============================] - 23s 221ms/step - loss: 0.0900 - accuracy: 0.9637 - val_loss: 0.1095 - val_accuracy: 0.9569\n",
            "Epoch 124/300\n",
            "106/105 [==============================] - 23s 220ms/step - loss: 0.0857 - accuracy: 0.9672 - val_loss: 0.1059 - val_accuracy: 0.9596\n",
            "Epoch 125/300\n",
            "106/105 [==============================] - 23s 220ms/step - loss: 0.0855 - accuracy: 0.9678 - val_loss: 0.1216 - val_accuracy: 0.9528\n",
            "Epoch 126/300\n",
            "106/105 [==============================] - 23s 219ms/step - loss: 0.0829 - accuracy: 0.9671 - val_loss: 0.1022 - val_accuracy: 0.9619\n",
            "Epoch 127/300\n",
            "106/105 [==============================] - 23s 220ms/step - loss: 0.0843 - accuracy: 0.9689 - val_loss: 0.1110 - val_accuracy: 0.9569\n",
            "Epoch 128/300\n",
            "106/105 [==============================] - 23s 219ms/step - loss: 0.0838 - accuracy: 0.9676 - val_loss: 0.1198 - val_accuracy: 0.9520\n",
            "Epoch 129/300\n",
            "106/105 [==============================] - 23s 220ms/step - loss: 0.0864 - accuracy: 0.9668 - val_loss: 0.1136 - val_accuracy: 0.9554\n",
            "Epoch 130/300\n",
            "106/105 [==============================] - 23s 219ms/step - loss: 0.0849 - accuracy: 0.9687 - val_loss: 0.1059 - val_accuracy: 0.9600\n",
            "Epoch 131/300\n",
            "106/105 [==============================] - 23s 221ms/step - loss: 0.0797 - accuracy: 0.9696 - val_loss: 0.1043 - val_accuracy: 0.9600\n",
            "Epoch 132/300\n",
            "106/105 [==============================] - 23s 218ms/step - loss: 0.0843 - accuracy: 0.9677 - val_loss: 0.1022 - val_accuracy: 0.9607\n",
            "Epoch 133/300\n",
            "106/105 [==============================] - 23s 219ms/step - loss: 0.0823 - accuracy: 0.9684 - val_loss: 0.1135 - val_accuracy: 0.9551\n",
            "Epoch 134/300\n",
            "106/105 [==============================] - 23s 219ms/step - loss: 0.0860 - accuracy: 0.9664 - val_loss: 0.1262 - val_accuracy: 0.9505\n",
            "Epoch 135/300\n",
            "106/105 [==============================] - 23s 218ms/step - loss: 0.0853 - accuracy: 0.9667 - val_loss: 0.1233 - val_accuracy: 0.9517\n",
            "Epoch 136/300\n",
            "106/105 [==============================] - 23s 220ms/step - loss: 0.0875 - accuracy: 0.9670 - val_loss: 0.1091 - val_accuracy: 0.9585\n",
            "Epoch 137/300\n",
            "106/105 [==============================] - 23s 219ms/step - loss: 0.0857 - accuracy: 0.9671 - val_loss: 0.1241 - val_accuracy: 0.9502\n",
            "Epoch 138/300\n",
            "106/105 [==============================] - 23s 221ms/step - loss: 0.0821 - accuracy: 0.9693 - val_loss: 0.1219 - val_accuracy: 0.9498\n",
            "Epoch 139/300\n",
            "106/105 [==============================] - 23s 220ms/step - loss: 0.0828 - accuracy: 0.9665 - val_loss: 0.1145 - val_accuracy: 0.9547\n",
            "Epoch 140/300\n",
            "106/105 [==============================] - 23s 220ms/step - loss: 0.0835 - accuracy: 0.9678 - val_loss: 0.1251 - val_accuracy: 0.9509\n",
            "Epoch 141/300\n",
            "106/105 [==============================] - 24s 222ms/step - loss: 0.0861 - accuracy: 0.9654 - val_loss: 0.1205 - val_accuracy: 0.9532\n",
            "Epoch 142/300\n",
            "106/105 [==============================] - 23s 221ms/step - loss: 0.0876 - accuracy: 0.9656 - val_loss: 0.1120 - val_accuracy: 0.9551\n",
            "Epoch 143/300\n",
            "106/105 [==============================] - 23s 219ms/step - loss: 0.0847 - accuracy: 0.9661 - val_loss: 0.1147 - val_accuracy: 0.9562\n",
            "Epoch 144/300\n",
            "106/105 [==============================] - 23s 220ms/step - loss: 0.0793 - accuracy: 0.9688 - val_loss: 0.1099 - val_accuracy: 0.9588\n",
            "Epoch 145/300\n",
            "106/105 [==============================] - 23s 220ms/step - loss: 0.0818 - accuracy: 0.9680 - val_loss: 0.1137 - val_accuracy: 0.9562\n",
            "Epoch 146/300\n",
            "106/105 [==============================] - 23s 220ms/step - loss: 0.0871 - accuracy: 0.9647 - val_loss: 0.1134 - val_accuracy: 0.9547\n",
            "Epoch 147/300\n",
            "106/105 [==============================] - 23s 219ms/step - loss: 0.0848 - accuracy: 0.9662 - val_loss: 0.1055 - val_accuracy: 0.9588\n",
            "Epoch 148/300\n",
            "106/105 [==============================] - 23s 221ms/step - loss: 0.0830 - accuracy: 0.9665 - val_loss: 0.1168 - val_accuracy: 0.9554\n",
            "Epoch 149/300\n",
            "106/105 [==============================] - 23s 220ms/step - loss: 0.0806 - accuracy: 0.9689 - val_loss: 0.1116 - val_accuracy: 0.9551\n",
            "Epoch 150/300\n",
            "106/105 [==============================] - 23s 220ms/step - loss: 0.0856 - accuracy: 0.9673 - val_loss: 0.1081 - val_accuracy: 0.9577\n",
            "Epoch 151/300\n",
            "106/105 [==============================] - 23s 221ms/step - loss: 0.0846 - accuracy: 0.9673 - val_loss: 0.1122 - val_accuracy: 0.9573\n",
            "Epoch 152/300\n",
            "106/105 [==============================] - 24s 224ms/step - loss: 0.0833 - accuracy: 0.9691 - val_loss: 0.1190 - val_accuracy: 0.9524\n",
            "Epoch 153/300\n",
            "106/105 [==============================] - 23s 221ms/step - loss: 0.0816 - accuracy: 0.9692 - val_loss: 0.1081 - val_accuracy: 0.9596\n",
            "Epoch 154/300\n",
            "106/105 [==============================] - 23s 221ms/step - loss: 0.0846 - accuracy: 0.9666 - val_loss: 0.1027 - val_accuracy: 0.9607\n",
            "Epoch 155/300\n",
            "106/105 [==============================] - 24s 222ms/step - loss: 0.0836 - accuracy: 0.9682 - val_loss: 0.1035 - val_accuracy: 0.9615\n",
            "Epoch 156/300\n",
            "106/105 [==============================] - 24s 222ms/step - loss: 0.0834 - accuracy: 0.9684 - val_loss: 0.1006 - val_accuracy: 0.9611\n",
            "Epoch 157/300\n",
            "106/105 [==============================] - 23s 222ms/step - loss: 0.0857 - accuracy: 0.9680 - val_loss: 0.1064 - val_accuracy: 0.9607\n",
            "Epoch 158/300\n",
            "106/105 [==============================] - 24s 223ms/step - loss: 0.0813 - accuracy: 0.9676 - val_loss: 0.1069 - val_accuracy: 0.9603\n",
            "Epoch 159/300\n",
            "106/105 [==============================] - 23s 219ms/step - loss: 0.0835 - accuracy: 0.9670 - val_loss: 0.0966 - val_accuracy: 0.9630\n",
            "Epoch 160/300\n",
            "106/105 [==============================] - 23s 219ms/step - loss: 0.0849 - accuracy: 0.9679 - val_loss: 0.1093 - val_accuracy: 0.9577\n",
            "Epoch 161/300\n",
            "106/105 [==============================] - 23s 221ms/step - loss: 0.0800 - accuracy: 0.9686 - val_loss: 0.1315 - val_accuracy: 0.9468\n",
            "Epoch 162/300\n",
            "106/105 [==============================] - 23s 221ms/step - loss: 0.0840 - accuracy: 0.9669 - val_loss: 0.1167 - val_accuracy: 0.9532\n",
            "Epoch 163/300\n",
            "106/105 [==============================] - 23s 220ms/step - loss: 0.0832 - accuracy: 0.9692 - val_loss: 0.1171 - val_accuracy: 0.9543\n",
            "Epoch 164/300\n",
            "106/105 [==============================] - 23s 218ms/step - loss: 0.0822 - accuracy: 0.9684 - val_loss: 0.1145 - val_accuracy: 0.9569\n",
            "Epoch 165/300\n",
            "106/105 [==============================] - 23s 218ms/step - loss: 0.0822 - accuracy: 0.9679 - val_loss: 0.1112 - val_accuracy: 0.9588\n",
            "Epoch 166/300\n",
            "106/105 [==============================] - 23s 218ms/step - loss: 0.0882 - accuracy: 0.9662 - val_loss: 0.1107 - val_accuracy: 0.9569\n",
            "Epoch 167/300\n",
            "106/105 [==============================] - 23s 218ms/step - loss: 0.0837 - accuracy: 0.9674 - val_loss: 0.1186 - val_accuracy: 0.9539\n",
            "Epoch 168/300\n",
            "106/105 [==============================] - 23s 219ms/step - loss: 0.0848 - accuracy: 0.9664 - val_loss: 0.1017 - val_accuracy: 0.9615\n",
            "Epoch 169/300\n",
            "106/105 [==============================] - 23s 220ms/step - loss: 0.0840 - accuracy: 0.9699 - val_loss: 0.1095 - val_accuracy: 0.9581\n",
            "Epoch 170/300\n",
            "106/105 [==============================] - 23s 218ms/step - loss: 0.0812 - accuracy: 0.9673 - val_loss: 0.1065 - val_accuracy: 0.9577\n",
            "Epoch 171/300\n",
            "106/105 [==============================] - 23s 219ms/step - loss: 0.0779 - accuracy: 0.9691 - val_loss: 0.1151 - val_accuracy: 0.9535\n",
            "Epoch 172/300\n",
            "106/105 [==============================] - 24s 222ms/step - loss: 0.0805 - accuracy: 0.9698 - val_loss: 0.1043 - val_accuracy: 0.9592\n",
            "Epoch 173/300\n",
            "106/105 [==============================] - 23s 220ms/step - loss: 0.0801 - accuracy: 0.9693 - val_loss: 0.1064 - val_accuracy: 0.9569\n",
            "Epoch 174/300\n",
            "106/105 [==============================] - 23s 219ms/step - loss: 0.0826 - accuracy: 0.9679 - val_loss: 0.1173 - val_accuracy: 0.9528\n",
            "Epoch 175/300\n",
            "106/105 [==============================] - 23s 219ms/step - loss: 0.0826 - accuracy: 0.9688 - val_loss: 0.1074 - val_accuracy: 0.9573\n",
            "Epoch 176/300\n",
            "106/105 [==============================] - 23s 220ms/step - loss: 0.0846 - accuracy: 0.9679 - val_loss: 0.1152 - val_accuracy: 0.9532\n",
            "Epoch 177/300\n",
            "106/105 [==============================] - 23s 219ms/step - loss: 0.0843 - accuracy: 0.9686 - val_loss: 0.1348 - val_accuracy: 0.9445\n",
            "Epoch 178/300\n",
            "106/105 [==============================] - 23s 217ms/step - loss: 0.0813 - accuracy: 0.9703 - val_loss: 0.1111 - val_accuracy: 0.9569\n",
            "Epoch 179/300\n",
            "106/105 [==============================] - 23s 221ms/step - loss: 0.0838 - accuracy: 0.9667 - val_loss: 0.1066 - val_accuracy: 0.9573\n",
            "Epoch 180/300\n",
            "106/105 [==============================] - 23s 218ms/step - loss: 0.0844 - accuracy: 0.9674 - val_loss: 0.1019 - val_accuracy: 0.9611\n",
            "Epoch 181/300\n",
            "106/105 [==============================] - 23s 219ms/step - loss: 0.0795 - accuracy: 0.9679 - val_loss: 0.1019 - val_accuracy: 0.9600\n",
            "Epoch 182/300\n",
            "106/105 [==============================] - 24s 222ms/step - loss: 0.0818 - accuracy: 0.9688 - val_loss: 0.1132 - val_accuracy: 0.9535\n",
            "Epoch 183/300\n",
            "106/105 [==============================] - 23s 218ms/step - loss: 0.0809 - accuracy: 0.9685 - val_loss: 0.1225 - val_accuracy: 0.9513\n",
            "Epoch 184/300\n",
            "106/105 [==============================] - 23s 217ms/step - loss: 0.0801 - accuracy: 0.9698 - val_loss: 0.1116 - val_accuracy: 0.9569\n",
            "Epoch 185/300\n",
            "106/105 [==============================] - 23s 217ms/step - loss: 0.0802 - accuracy: 0.9694 - val_loss: 0.1050 - val_accuracy: 0.9607\n",
            "Epoch 186/300\n",
            "106/105 [==============================] - 23s 218ms/step - loss: 0.0846 - accuracy: 0.9690 - val_loss: 0.1271 - val_accuracy: 0.9486\n",
            "Epoch 187/300\n",
            "106/105 [==============================] - 23s 217ms/step - loss: 0.0821 - accuracy: 0.9684 - val_loss: 0.1186 - val_accuracy: 0.9558\n",
            "Epoch 188/300\n",
            "106/105 [==============================] - 23s 216ms/step - loss: 0.0808 - accuracy: 0.9692 - val_loss: 0.1181 - val_accuracy: 0.9535\n",
            "Epoch 189/300\n",
            "106/105 [==============================] - 23s 219ms/step - loss: 0.0827 - accuracy: 0.9686 - val_loss: 0.1021 - val_accuracy: 0.9615\n",
            "Epoch 190/300\n",
            "106/105 [==============================] - 23s 219ms/step - loss: 0.0809 - accuracy: 0.9697 - val_loss: 0.1145 - val_accuracy: 0.9562\n",
            "Epoch 191/300\n",
            "106/105 [==============================] - 23s 218ms/step - loss: 0.0785 - accuracy: 0.9691 - val_loss: 0.1150 - val_accuracy: 0.9547\n",
            "Epoch 192/300\n",
            "106/105 [==============================] - 23s 219ms/step - loss: 0.0812 - accuracy: 0.9691 - val_loss: 0.1231 - val_accuracy: 0.9505\n",
            "Epoch 193/300\n",
            "106/105 [==============================] - 23s 218ms/step - loss: 0.0834 - accuracy: 0.9701 - val_loss: 0.1022 - val_accuracy: 0.9615\n",
            "Epoch 194/300\n",
            "106/105 [==============================] - 23s 216ms/step - loss: 0.0795 - accuracy: 0.9696 - val_loss: 0.1159 - val_accuracy: 0.9543\n",
            "Epoch 195/300\n",
            "106/105 [==============================] - 23s 217ms/step - loss: 0.0826 - accuracy: 0.9684 - val_loss: 0.1149 - val_accuracy: 0.9547\n",
            "Epoch 196/300\n",
            "106/105 [==============================] - 23s 216ms/step - loss: 0.0807 - accuracy: 0.9683 - val_loss: 0.1046 - val_accuracy: 0.9607\n",
            "Epoch 197/300\n",
            "106/105 [==============================] - 23s 216ms/step - loss: 0.0790 - accuracy: 0.9700 - val_loss: 0.1173 - val_accuracy: 0.9539\n",
            "Epoch 198/300\n",
            "106/105 [==============================] - 23s 216ms/step - loss: 0.0800 - accuracy: 0.9676 - val_loss: 0.1174 - val_accuracy: 0.9543\n",
            "Epoch 199/300\n",
            "106/105 [==============================] - 23s 217ms/step - loss: 0.0824 - accuracy: 0.9716 - val_loss: 0.1109 - val_accuracy: 0.9573\n",
            "Epoch 200/300\n",
            "106/105 [==============================] - 23s 217ms/step - loss: 0.0826 - accuracy: 0.9672 - val_loss: 0.1093 - val_accuracy: 0.9577\n",
            "Epoch 201/300\n",
            "106/105 [==============================] - 23s 217ms/step - loss: 0.0828 - accuracy: 0.9691 - val_loss: 0.1314 - val_accuracy: 0.9490\n",
            "Epoch 202/300\n",
            "106/105 [==============================] - 23s 216ms/step - loss: 0.0844 - accuracy: 0.9665 - val_loss: 0.1015 - val_accuracy: 0.9615\n",
            "Epoch 203/300\n",
            "106/105 [==============================] - 23s 216ms/step - loss: 0.0832 - accuracy: 0.9684 - val_loss: 0.1133 - val_accuracy: 0.9562\n",
            "Epoch 204/300\n",
            "106/105 [==============================] - 23s 217ms/step - loss: 0.0798 - accuracy: 0.9667 - val_loss: 0.1067 - val_accuracy: 0.9581\n",
            "Epoch 205/300\n",
            "106/105 [==============================] - 23s 215ms/step - loss: 0.0767 - accuracy: 0.9700 - val_loss: 0.1016 - val_accuracy: 0.9619\n",
            "Epoch 206/300\n",
            "106/105 [==============================] - 23s 218ms/step - loss: 0.0790 - accuracy: 0.9704 - val_loss: 0.1173 - val_accuracy: 0.9547\n",
            "Epoch 207/300\n",
            "106/105 [==============================] - 23s 218ms/step - loss: 0.0775 - accuracy: 0.9702 - val_loss: 0.1151 - val_accuracy: 0.9517\n",
            "Epoch 208/300\n",
            "106/105 [==============================] - 23s 218ms/step - loss: 0.0819 - accuracy: 0.9698 - val_loss: 0.1112 - val_accuracy: 0.9581\n",
            "Epoch 209/300\n",
            "106/105 [==============================] - 23s 216ms/step - loss: 0.0816 - accuracy: 0.9685 - val_loss: 0.1093 - val_accuracy: 0.9573\n",
            "Epoch 210/300\n",
            "106/105 [==============================] - 23s 216ms/step - loss: 0.0814 - accuracy: 0.9692 - val_loss: 0.1211 - val_accuracy: 0.9539\n",
            "Epoch 211/300\n",
            "106/105 [==============================] - 23s 216ms/step - loss: 0.0816 - accuracy: 0.9667 - val_loss: 0.1284 - val_accuracy: 0.9502\n",
            "Epoch 212/300\n",
            "106/105 [==============================] - 23s 215ms/step - loss: 0.0787 - accuracy: 0.9713 - val_loss: 0.1314 - val_accuracy: 0.9483\n",
            "Epoch 213/300\n",
            "106/105 [==============================] - 23s 217ms/step - loss: 0.0791 - accuracy: 0.9695 - val_loss: 0.1194 - val_accuracy: 0.9528\n",
            "Epoch 214/300\n",
            "106/105 [==============================] - 23s 216ms/step - loss: 0.0819 - accuracy: 0.9679 - val_loss: 0.1177 - val_accuracy: 0.9535\n",
            "Epoch 215/300\n",
            "106/105 [==============================] - 23s 215ms/step - loss: 0.0827 - accuracy: 0.9682 - val_loss: 0.1193 - val_accuracy: 0.9543\n",
            "Epoch 216/300\n",
            "106/105 [==============================] - 23s 214ms/step - loss: 0.0836 - accuracy: 0.9692 - val_loss: 0.1148 - val_accuracy: 0.9566\n",
            "Epoch 217/300\n",
            "106/105 [==============================] - 23s 215ms/step - loss: 0.0802 - accuracy: 0.9684 - val_loss: 0.1166 - val_accuracy: 0.9539\n",
            "Epoch 218/300\n",
            "106/105 [==============================] - 23s 215ms/step - loss: 0.0796 - accuracy: 0.9701 - val_loss: 0.0922 - val_accuracy: 0.9634\n",
            "Epoch 219/300\n",
            "106/105 [==============================] - 23s 216ms/step - loss: 0.0763 - accuracy: 0.9703 - val_loss: 0.1063 - val_accuracy: 0.9603\n",
            "Epoch 220/300\n",
            "106/105 [==============================] - 23s 215ms/step - loss: 0.0745 - accuracy: 0.9718 - val_loss: 0.1166 - val_accuracy: 0.9551\n",
            "Epoch 221/300\n",
            "106/105 [==============================] - 23s 219ms/step - loss: 0.0800 - accuracy: 0.9701 - val_loss: 0.0964 - val_accuracy: 0.9622\n",
            "Epoch 222/300\n",
            "106/105 [==============================] - 23s 217ms/step - loss: 0.0816 - accuracy: 0.9709 - val_loss: 0.1009 - val_accuracy: 0.9619\n",
            "Epoch 223/300\n",
            "106/105 [==============================] - 23s 215ms/step - loss: 0.0789 - accuracy: 0.9699 - val_loss: 0.1248 - val_accuracy: 0.9513\n",
            "Epoch 224/300\n",
            "106/105 [==============================] - 23s 216ms/step - loss: 0.0805 - accuracy: 0.9685 - val_loss: 0.1022 - val_accuracy: 0.9611\n",
            "Epoch 225/300\n",
            "106/105 [==============================] - 23s 221ms/step - loss: 0.0762 - accuracy: 0.9684 - val_loss: 0.1019 - val_accuracy: 0.9611\n",
            "Epoch 226/300\n",
            "106/105 [==============================] - 24s 222ms/step - loss: 0.0785 - accuracy: 0.9700 - val_loss: 0.1010 - val_accuracy: 0.9615\n",
            "Epoch 227/300\n",
            "106/105 [==============================] - 24s 228ms/step - loss: 0.0781 - accuracy: 0.9708 - val_loss: 0.1152 - val_accuracy: 0.9551\n",
            "Epoch 228/300\n",
            "106/105 [==============================] - 24s 226ms/step - loss: 0.0826 - accuracy: 0.9691 - val_loss: 0.1130 - val_accuracy: 0.9573\n",
            "Epoch 229/300\n",
            "106/105 [==============================] - 24s 228ms/step - loss: 0.0784 - accuracy: 0.9706 - val_loss: 0.1099 - val_accuracy: 0.9585\n",
            "Epoch 230/300\n",
            "106/105 [==============================] - 24s 226ms/step - loss: 0.0817 - accuracy: 0.9698 - val_loss: 0.1087 - val_accuracy: 0.9585\n",
            "Epoch 231/300\n",
            "106/105 [==============================] - 24s 223ms/step - loss: 0.0800 - accuracy: 0.9681 - val_loss: 0.1046 - val_accuracy: 0.9607\n",
            "Epoch 232/300\n",
            "106/105 [==============================] - 23s 220ms/step - loss: 0.0782 - accuracy: 0.9696 - val_loss: 0.1244 - val_accuracy: 0.9502\n",
            "Epoch 233/300\n",
            "106/105 [==============================] - 24s 222ms/step - loss: 0.0781 - accuracy: 0.9707 - val_loss: 0.1232 - val_accuracy: 0.9513\n",
            "Epoch 234/300\n",
            "106/105 [==============================] - 23s 221ms/step - loss: 0.0818 - accuracy: 0.9675 - val_loss: 0.1167 - val_accuracy: 0.9547\n",
            "Epoch 235/300\n",
            "106/105 [==============================] - 24s 222ms/step - loss: 0.0827 - accuracy: 0.9697 - val_loss: 0.1107 - val_accuracy: 0.9562\n",
            "Epoch 236/300\n",
            "106/105 [==============================] - 23s 219ms/step - loss: 0.0753 - accuracy: 0.9709 - val_loss: 0.1100 - val_accuracy: 0.9551\n",
            "Epoch 237/300\n",
            "106/105 [==============================] - 24s 222ms/step - loss: 0.0778 - accuracy: 0.9710 - val_loss: 0.0995 - val_accuracy: 0.9615\n",
            "Epoch 238/300\n",
            "106/105 [==============================] - 24s 222ms/step - loss: 0.0805 - accuracy: 0.9685 - val_loss: 0.1014 - val_accuracy: 0.9603\n",
            "Epoch 239/300\n",
            "106/105 [==============================] - 24s 223ms/step - loss: 0.0757 - accuracy: 0.9692 - val_loss: 0.1182 - val_accuracy: 0.9558\n",
            "Epoch 240/300\n",
            "106/105 [==============================] - 23s 222ms/step - loss: 0.0782 - accuracy: 0.9695 - val_loss: 0.1114 - val_accuracy: 0.9592\n",
            "Epoch 241/300\n",
            "106/105 [==============================] - 23s 220ms/step - loss: 0.0798 - accuracy: 0.9697 - val_loss: 0.1113 - val_accuracy: 0.9585\n",
            "Epoch 242/300\n",
            "106/105 [==============================] - 23s 219ms/step - loss: 0.0768 - accuracy: 0.9707 - val_loss: 0.1233 - val_accuracy: 0.9532\n",
            "Epoch 243/300\n",
            "106/105 [==============================] - 23s 218ms/step - loss: 0.0795 - accuracy: 0.9693 - val_loss: 0.1048 - val_accuracy: 0.9607\n",
            "Epoch 244/300\n",
            "106/105 [==============================] - 23s 219ms/step - loss: 0.0753 - accuracy: 0.9701 - val_loss: 0.1123 - val_accuracy: 0.9566\n",
            "Epoch 245/300\n",
            "106/105 [==============================] - 23s 221ms/step - loss: 0.0784 - accuracy: 0.9688 - val_loss: 0.1222 - val_accuracy: 0.9524\n",
            "Epoch 246/300\n",
            "106/105 [==============================] - 23s 221ms/step - loss: 0.0757 - accuracy: 0.9720 - val_loss: 0.1210 - val_accuracy: 0.9551\n",
            "Epoch 247/300\n",
            "106/105 [==============================] - 23s 220ms/step - loss: 0.0769 - accuracy: 0.9712 - val_loss: 0.1188 - val_accuracy: 0.9551\n",
            "Epoch 248/300\n",
            "106/105 [==============================] - 23s 220ms/step - loss: 0.0776 - accuracy: 0.9696 - val_loss: 0.1055 - val_accuracy: 0.9615\n",
            "Epoch 249/300\n",
            "106/105 [==============================] - 23s 220ms/step - loss: 0.0780 - accuracy: 0.9685 - val_loss: 0.1026 - val_accuracy: 0.9630\n",
            "Epoch 250/300\n",
            "106/105 [==============================] - 23s 218ms/step - loss: 0.0814 - accuracy: 0.9696 - val_loss: 0.1119 - val_accuracy: 0.9569\n",
            "Epoch 251/300\n",
            "106/105 [==============================] - 23s 218ms/step - loss: 0.0814 - accuracy: 0.9687 - val_loss: 0.0988 - val_accuracy: 0.9622\n",
            "Epoch 252/300\n",
            "106/105 [==============================] - 24s 223ms/step - loss: 0.0801 - accuracy: 0.9689 - val_loss: 0.1206 - val_accuracy: 0.9513\n",
            "Epoch 253/300\n",
            "106/105 [==============================] - 24s 222ms/step - loss: 0.0792 - accuracy: 0.9691 - val_loss: 0.0965 - val_accuracy: 0.9634\n",
            "Epoch 254/300\n",
            "106/105 [==============================] - 23s 221ms/step - loss: 0.0770 - accuracy: 0.9694 - val_loss: 0.1031 - val_accuracy: 0.9637\n",
            "Epoch 255/300\n",
            "106/105 [==============================] - 24s 225ms/step - loss: 0.0743 - accuracy: 0.9705 - val_loss: 0.1117 - val_accuracy: 0.9577\n",
            "Epoch 256/300\n",
            "106/105 [==============================] - 24s 224ms/step - loss: 0.0778 - accuracy: 0.9718 - val_loss: 0.1125 - val_accuracy: 0.9588\n",
            "Epoch 257/300\n",
            "106/105 [==============================] - 23s 221ms/step - loss: 0.0783 - accuracy: 0.9694 - val_loss: 0.0921 - val_accuracy: 0.9653\n",
            "Epoch 258/300\n",
            "106/105 [==============================] - 24s 222ms/step - loss: 0.0805 - accuracy: 0.9695 - val_loss: 0.1042 - val_accuracy: 0.9596\n",
            "Epoch 259/300\n",
            "106/105 [==============================] - 24s 226ms/step - loss: 0.0770 - accuracy: 0.9700 - val_loss: 0.1215 - val_accuracy: 0.9539\n",
            "Epoch 260/300\n",
            "106/105 [==============================] - 23s 219ms/step - loss: 0.0760 - accuracy: 0.9692 - val_loss: 0.1013 - val_accuracy: 0.9611\n",
            "Epoch 261/300\n",
            "106/105 [==============================] - 23s 218ms/step - loss: 0.0760 - accuracy: 0.9702 - val_loss: 0.1232 - val_accuracy: 0.9505\n",
            "Epoch 262/300\n",
            "106/105 [==============================] - 23s 219ms/step - loss: 0.0819 - accuracy: 0.9687 - val_loss: 0.1234 - val_accuracy: 0.9513\n",
            "Epoch 263/300\n",
            "106/105 [==============================] - 23s 218ms/step - loss: 0.0789 - accuracy: 0.9700 - val_loss: 0.1175 - val_accuracy: 0.9551\n",
            "Epoch 264/300\n",
            "106/105 [==============================] - 23s 217ms/step - loss: 0.0787 - accuracy: 0.9708 - val_loss: 0.1099 - val_accuracy: 0.9585\n",
            "Epoch 265/300\n",
            "106/105 [==============================] - 23s 218ms/step - loss: 0.0742 - accuracy: 0.9717 - val_loss: 0.1038 - val_accuracy: 0.9600\n",
            "Epoch 266/300\n",
            "106/105 [==============================] - 23s 219ms/step - loss: 0.0729 - accuracy: 0.9741 - val_loss: 0.0931 - val_accuracy: 0.9664\n",
            "Epoch 267/300\n",
            "106/105 [==============================] - 23s 216ms/step - loss: 0.0817 - accuracy: 0.9692 - val_loss: 0.1169 - val_accuracy: 0.9520\n",
            "Epoch 268/300\n",
            "106/105 [==============================] - 23s 217ms/step - loss: 0.0762 - accuracy: 0.9708 - val_loss: 0.1148 - val_accuracy: 0.9539\n",
            "Epoch 269/300\n",
            "106/105 [==============================] - 23s 218ms/step - loss: 0.0743 - accuracy: 0.9720 - val_loss: 0.1083 - val_accuracy: 0.9573\n",
            "Epoch 270/300\n",
            "106/105 [==============================] - 23s 219ms/step - loss: 0.0743 - accuracy: 0.9719 - val_loss: 0.1240 - val_accuracy: 0.9520\n",
            "Epoch 271/300\n",
            "106/105 [==============================] - 23s 218ms/step - loss: 0.0722 - accuracy: 0.9714 - val_loss: 0.1094 - val_accuracy: 0.9573\n",
            "Epoch 272/300\n",
            "106/105 [==============================] - 23s 217ms/step - loss: 0.0741 - accuracy: 0.9719 - val_loss: 0.1182 - val_accuracy: 0.9543\n",
            "Epoch 273/300\n",
            "106/105 [==============================] - 23s 218ms/step - loss: 0.0770 - accuracy: 0.9700 - val_loss: 0.1221 - val_accuracy: 0.9547\n",
            "Epoch 274/300\n",
            "106/105 [==============================] - 23s 217ms/step - loss: 0.0809 - accuracy: 0.9706 - val_loss: 0.1220 - val_accuracy: 0.9543\n",
            "Epoch 275/300\n",
            "106/105 [==============================] - 23s 216ms/step - loss: 0.0767 - accuracy: 0.9702 - val_loss: 0.1078 - val_accuracy: 0.9592\n",
            "Epoch 276/300\n",
            "106/105 [==============================] - 23s 218ms/step - loss: 0.0786 - accuracy: 0.9696 - val_loss: 0.1172 - val_accuracy: 0.9543\n",
            "Epoch 277/300\n",
            "106/105 [==============================] - 23s 217ms/step - loss: 0.0736 - accuracy: 0.9728 - val_loss: 0.1143 - val_accuracy: 0.9569\n",
            "Epoch 278/300\n",
            "106/105 [==============================] - 23s 215ms/step - loss: 0.0781 - accuracy: 0.9696 - val_loss: 0.1214 - val_accuracy: 0.9520\n",
            "Epoch 279/300\n",
            "106/105 [==============================] - 23s 216ms/step - loss: 0.0740 - accuracy: 0.9719 - val_loss: 0.1274 - val_accuracy: 0.9490\n",
            "Epoch 280/300\n",
            "106/105 [==============================] - 23s 215ms/step - loss: 0.0814 - accuracy: 0.9690 - val_loss: 0.1175 - val_accuracy: 0.9566\n",
            "Epoch 281/300\n",
            "106/105 [==============================] - 23s 215ms/step - loss: 0.0731 - accuracy: 0.9714 - val_loss: 0.1066 - val_accuracy: 0.9596\n",
            "Epoch 282/300\n",
            "106/105 [==============================] - 23s 214ms/step - loss: 0.0804 - accuracy: 0.9695 - val_loss: 0.0892 - val_accuracy: 0.9660\n",
            "Epoch 283/300\n",
            "106/105 [==============================] - 23s 214ms/step - loss: 0.0761 - accuracy: 0.9701 - val_loss: 0.1075 - val_accuracy: 0.9581\n",
            "Epoch 284/300\n",
            "106/105 [==============================] - 23s 215ms/step - loss: 0.0762 - accuracy: 0.9709 - val_loss: 0.1423 - val_accuracy: 0.9426\n",
            "Epoch 285/300\n",
            "106/105 [==============================] - 23s 213ms/step - loss: 0.0761 - accuracy: 0.9719 - val_loss: 0.0990 - val_accuracy: 0.9611\n",
            "Epoch 286/300\n",
            "106/105 [==============================] - 23s 217ms/step - loss: 0.0756 - accuracy: 0.9708 - val_loss: 0.1097 - val_accuracy: 0.9573\n",
            "Epoch 287/300\n",
            "106/105 [==============================] - 23s 217ms/step - loss: 0.0726 - accuracy: 0.9721 - val_loss: 0.0938 - val_accuracy: 0.9656\n",
            "Epoch 288/300\n",
            "106/105 [==============================] - 23s 214ms/step - loss: 0.0765 - accuracy: 0.9714 - val_loss: 0.1192 - val_accuracy: 0.9535\n",
            "Epoch 289/300\n",
            "106/105 [==============================] - 23s 213ms/step - loss: 0.0799 - accuracy: 0.9693 - val_loss: 0.0919 - val_accuracy: 0.9668\n",
            "Epoch 290/300\n",
            "106/105 [==============================] - 23s 215ms/step - loss: 0.0802 - accuracy: 0.9702 - val_loss: 0.0920 - val_accuracy: 0.9653\n",
            "Epoch 291/300\n",
            "106/105 [==============================] - 23s 215ms/step - loss: 0.0771 - accuracy: 0.9699 - val_loss: 0.1152 - val_accuracy: 0.9532\n",
            "Epoch 292/300\n",
            "106/105 [==============================] - 23s 215ms/step - loss: 0.0786 - accuracy: 0.9699 - val_loss: 0.1073 - val_accuracy: 0.9588\n",
            "Epoch 293/300\n",
            "106/105 [==============================] - 23s 214ms/step - loss: 0.0744 - accuracy: 0.9712 - val_loss: 0.0924 - val_accuracy: 0.9645\n",
            "Epoch 294/300\n",
            "106/105 [==============================] - 23s 216ms/step - loss: 0.0732 - accuracy: 0.9724 - val_loss: 0.1023 - val_accuracy: 0.9603\n",
            "Epoch 295/300\n",
            "106/105 [==============================] - 23s 213ms/step - loss: 0.0802 - accuracy: 0.9701 - val_loss: 0.1085 - val_accuracy: 0.9581\n",
            "Epoch 296/300\n",
            "106/105 [==============================] - 23s 214ms/step - loss: 0.0755 - accuracy: 0.9701 - val_loss: 0.1032 - val_accuracy: 0.9607\n",
            "Epoch 297/300\n",
            "106/105 [==============================] - 23s 216ms/step - loss: 0.0770 - accuracy: 0.9693 - val_loss: 0.1109 - val_accuracy: 0.9566\n",
            "Epoch 298/300\n",
            "106/105 [==============================] - 23s 214ms/step - loss: 0.0738 - accuracy: 0.9714 - val_loss: 0.1177 - val_accuracy: 0.9520\n",
            "Epoch 299/300\n",
            "106/105 [==============================] - 23s 214ms/step - loss: 0.0736 - accuracy: 0.9718 - val_loss: 0.1095 - val_accuracy: 0.9581\n",
            "Epoch 300/300\n",
            "106/105 [==============================] - 23s 216ms/step - loss: 0.0701 - accuracy: 0.9744 - val_loss: 0.1118 - val_accuracy: 0.9558\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9YaBDzgTmy9o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Resnet\n",
        "def convo_block(y, filtros, num_conv, res=0):\n",
        "\n",
        "    if (res):\n",
        "        x=y\n",
        "\n",
        "    y=layers.Conv2D(filtros, kernel_size=(3, 3), strides=(2,2), padding='same')(y)\n",
        "    \n",
        "    for i in range(num_conv):\n",
        "        y=layers.Conv2D(filtros, kernel_size=(3, 3), strides=(1,1), padding='same')(y)\n",
        "        y=layers.BatchNormalization()(y)\n",
        "        y=layers.GaussianNoise(0.3)(y)\n",
        "        y=layers.ReLU()(y)\n",
        "\n",
        "    y=layers.Conv2D(filtros, kernel_size=(3, 3), strides=(1,1), padding='same')(y)\n",
        "    y=layers.BatchNormalization()(y)\n",
        "    y=layers.GaussianNoise(0.3)(y)\n",
        "\n",
        "    if (res):\n",
        "        \n",
        "        x=layers.Conv2D(filtros, kernel_size=(1, 1), strides=(2,2),padding='same')(x)\n",
        "        y=layers.add([x, y])\n",
        "        y=layers.ReLU()(y)\n",
        "\n",
        "    else:\n",
        "        y=layers.MaxPooling2D(pool_size=(2, 2))(y)\n",
        "        \n",
        "    return y\n",
        "\n",
        "\n",
        "def generate_model(num_conv_blocks):\n",
        "    \n",
        "    filtros = 8\n",
        "    n_conv = 2\n",
        "    input_layer = layers.Input(shape=(100,100,3))\n",
        "    x = convo_block(input_layer, filtros, n_conv)\n",
        "    #Convolutional part\n",
        "    for i in range(num_conv_blocks-1):\n",
        "      x = convo_block(x, filtros, n_conv, res=1)\n",
        "\n",
        "    x=layers.Flatten()(x)\n",
        "    x=layers.Dense(64)(x)\n",
        "    x=layers.BatchNormalization()(x)\n",
        "    x=layers.GaussianNoise(0.3)(x)\n",
        "    x=layers.ReLU()(x)\n",
        "\n",
        "    x=layers.Dense(2, activation='softmax')(x)\n",
        "    model = models.Model(inputs=[input_layer], outputs=[x])\n",
        "\n",
        "    return model\n",
        " "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sj3wMUuOmzoJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "88c6241d-7fb1-498d-c002-107752f8ab82"
      },
      "source": [
        "    \n",
        "model = generate_model(2)\n",
        "model.summary()\n",
        "\n",
        "\n",
        "## OPTIM AND COMPILE\n",
        "opt = SGD(lr=0.1, decay=1e-6)\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=opt,\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# DEFINE A LEARNING RATE SCHEDULER\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, cooldown=1,\n",
        "                              patience=10, min_lr=0.005)\n",
        "\n",
        "## TRAINING with DA and LRA\n",
        "\n",
        "batch_size = 100\n",
        "epochs = 500\n",
        "\n",
        "history=model.fit_generator(datagen.flow(x_train, y_train,batch_size=batch_size),\n",
        "                            steps_per_epoch=len(x_train) / batch_size, \n",
        "                            epochs=epochs,\n",
        "                            validation_data=(x_test, y_test),\n",
        "                            callbacks=[reduce_lr],\n",
        "                            verbose=1)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_3\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_3 (InputLayer)            (None, 100, 100, 3)  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 50, 50, 8)    224         input_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 50, 50, 8)    584         conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_15 (BatchNo (None, 50, 50, 8)    32          conv2d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "gaussian_noise_15 (GaussianNois (None, 50, 50, 8)    0           batch_normalization_15[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2D)  (None, 25, 25, 8)    0           gaussian_noise_15[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 13, 13, 8)    584         max_pooling2d_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, 13, 13, 8)    584         conv2d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_16 (BatchNo (None, 13, 13, 8)    32          conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_21 (Conv2D)              (None, 13, 13, 8)    72          max_pooling2d_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "gaussian_noise_16 (GaussianNois (None, 13, 13, 8)    0           batch_normalization_16[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "add_5 (Add)                     (None, 13, 13, 8)    0           conv2d_21[0][0]                  \n",
            "                                                                 gaussian_noise_16[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_13 (ReLU)                 (None, 13, 13, 8)    0           add_5[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "flatten_3 (Flatten)             (None, 1352)         0           re_lu_13[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_5 (Dense)                 (None, 64)           86592       flatten_3[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_17 (BatchNo (None, 64)           256         dense_5[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "gaussian_noise_17 (GaussianNois (None, 64)           0           batch_normalization_17[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_14 (ReLU)                 (None, 64)           0           gaussian_noise_17[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "dense_6 (Dense)                 (None, 2)            130         re_lu_14[0][0]                   \n",
            "==================================================================================================\n",
            "Total params: 89,090\n",
            "Trainable params: 88,930\n",
            "Non-trainable params: 160\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/500\n",
            "106/105 [==============================] - 23s 214ms/step - loss: 0.5254 - accuracy: 0.7560 - val_loss: 0.5196 - val_accuracy: 0.7885\n",
            "Epoch 2/500\n",
            "106/105 [==============================] - 22s 208ms/step - loss: 0.4519 - accuracy: 0.7918 - val_loss: 0.4312 - val_accuracy: 0.8168\n",
            "Epoch 3/500\n",
            "106/105 [==============================] - 22s 208ms/step - loss: 0.4250 - accuracy: 0.8079 - val_loss: 0.4199 - val_accuracy: 0.8369\n",
            "Epoch 4/500\n",
            "106/105 [==============================] - 22s 208ms/step - loss: 0.4015 - accuracy: 0.8178 - val_loss: 0.4599 - val_accuracy: 0.7787\n",
            "Epoch 5/500\n",
            "106/105 [==============================] - 22s 209ms/step - loss: 0.3921 - accuracy: 0.8217 - val_loss: 0.3384 - val_accuracy: 0.8516\n",
            "Epoch 6/500\n",
            "106/105 [==============================] - 22s 207ms/step - loss: 0.3885 - accuracy: 0.8246 - val_loss: 0.3420 - val_accuracy: 0.8471\n",
            "Epoch 7/500\n",
            "106/105 [==============================] - 22s 209ms/step - loss: 0.3833 - accuracy: 0.8293 - val_loss: 0.3636 - val_accuracy: 0.8421\n",
            "Epoch 8/500\n",
            "106/105 [==============================] - 22s 206ms/step - loss: 0.3820 - accuracy: 0.8302 - val_loss: 0.3336 - val_accuracy: 0.8493\n",
            "Epoch 9/500\n",
            "106/105 [==============================] - 22s 205ms/step - loss: 0.3763 - accuracy: 0.8334 - val_loss: 0.3524 - val_accuracy: 0.8444\n",
            "Epoch 10/500\n",
            "106/105 [==============================] - 22s 204ms/step - loss: 0.3690 - accuracy: 0.8370 - val_loss: 0.3675 - val_accuracy: 0.8433\n",
            "Epoch 11/500\n",
            "106/105 [==============================] - 22s 206ms/step - loss: 0.3706 - accuracy: 0.8356 - val_loss: 0.3788 - val_accuracy: 0.8278\n",
            "Epoch 12/500\n",
            "106/105 [==============================] - 23s 214ms/step - loss: 0.3643 - accuracy: 0.8376 - val_loss: 0.3211 - val_accuracy: 0.8614\n",
            "Epoch 13/500\n",
            "106/105 [==============================] - 23s 213ms/step - loss: 0.3659 - accuracy: 0.8368 - val_loss: 0.3372 - val_accuracy: 0.8508\n",
            "Epoch 14/500\n",
            "106/105 [==============================] - 23s 213ms/step - loss: 0.3608 - accuracy: 0.8442 - val_loss: 0.3715 - val_accuracy: 0.8369\n",
            "Epoch 15/500\n",
            "106/105 [==============================] - 22s 209ms/step - loss: 0.3583 - accuracy: 0.8396 - val_loss: 0.3143 - val_accuracy: 0.8614\n",
            "Epoch 16/500\n",
            "106/105 [==============================] - 22s 209ms/step - loss: 0.3538 - accuracy: 0.8446 - val_loss: 0.3023 - val_accuracy: 0.8708\n",
            "Epoch 17/500\n",
            "106/105 [==============================] - 22s 208ms/step - loss: 0.3553 - accuracy: 0.8398 - val_loss: 0.3029 - val_accuracy: 0.8697\n",
            "Epoch 18/500\n",
            "106/105 [==============================] - 22s 206ms/step - loss: 0.3446 - accuracy: 0.8525 - val_loss: 0.3173 - val_accuracy: 0.8640\n",
            "Epoch 19/500\n",
            "106/105 [==============================] - 22s 207ms/step - loss: 0.3443 - accuracy: 0.8486 - val_loss: 0.2994 - val_accuracy: 0.8750\n",
            "Epoch 20/500\n",
            "106/105 [==============================] - 22s 206ms/step - loss: 0.3473 - accuracy: 0.8481 - val_loss: 0.2953 - val_accuracy: 0.8833\n",
            "Epoch 21/500\n",
            "106/105 [==============================] - 22s 209ms/step - loss: 0.3399 - accuracy: 0.8513 - val_loss: 0.3233 - val_accuracy: 0.8591\n",
            "Epoch 22/500\n",
            "106/105 [==============================] - 22s 209ms/step - loss: 0.3409 - accuracy: 0.8491 - val_loss: 0.3156 - val_accuracy: 0.8629\n",
            "Epoch 23/500\n",
            "106/105 [==============================] - 22s 209ms/step - loss: 0.3335 - accuracy: 0.8544 - val_loss: 0.3053 - val_accuracy: 0.8780\n",
            "Epoch 24/500\n",
            "106/105 [==============================] - 22s 208ms/step - loss: 0.3393 - accuracy: 0.8550 - val_loss: 0.2993 - val_accuracy: 0.8784\n",
            "Epoch 25/500\n",
            "106/105 [==============================] - 22s 208ms/step - loss: 0.3342 - accuracy: 0.8531 - val_loss: 0.3068 - val_accuracy: 0.8686\n",
            "Epoch 26/500\n",
            "106/105 [==============================] - 22s 210ms/step - loss: 0.3288 - accuracy: 0.8559 - val_loss: 0.2974 - val_accuracy: 0.8742\n",
            "Epoch 27/500\n",
            "106/105 [==============================] - 22s 212ms/step - loss: 0.3318 - accuracy: 0.8539 - val_loss: 0.2875 - val_accuracy: 0.8875\n",
            "Epoch 28/500\n",
            "106/105 [==============================] - 22s 210ms/step - loss: 0.3229 - accuracy: 0.8571 - val_loss: 0.2738 - val_accuracy: 0.8875\n",
            "Epoch 29/500\n",
            "106/105 [==============================] - 22s 211ms/step - loss: 0.3205 - accuracy: 0.8592 - val_loss: 0.3019 - val_accuracy: 0.8750\n",
            "Epoch 30/500\n",
            "106/105 [==============================] - 23s 213ms/step - loss: 0.3177 - accuracy: 0.8637 - val_loss: 0.2861 - val_accuracy: 0.8792\n",
            "Epoch 31/500\n",
            "106/105 [==============================] - 23s 213ms/step - loss: 0.3141 - accuracy: 0.8639 - val_loss: 0.2527 - val_accuracy: 0.8950\n",
            "Epoch 32/500\n",
            "106/105 [==============================] - 23s 213ms/step - loss: 0.3129 - accuracy: 0.8668 - val_loss: 0.2655 - val_accuracy: 0.8909\n",
            "Epoch 33/500\n",
            "106/105 [==============================] - 22s 212ms/step - loss: 0.3116 - accuracy: 0.8688 - val_loss: 0.3001 - val_accuracy: 0.8712\n",
            "Epoch 34/500\n",
            "106/105 [==============================] - 22s 212ms/step - loss: 0.3024 - accuracy: 0.8691 - val_loss: 0.2659 - val_accuracy: 0.8965\n",
            "Epoch 35/500\n",
            "106/105 [==============================] - 23s 213ms/step - loss: 0.2947 - accuracy: 0.8748 - val_loss: 0.2377 - val_accuracy: 0.9029\n",
            "Epoch 36/500\n",
            "106/105 [==============================] - 22s 210ms/step - loss: 0.3034 - accuracy: 0.8727 - val_loss: 0.2451 - val_accuracy: 0.8946\n",
            "Epoch 37/500\n",
            "106/105 [==============================] - 22s 211ms/step - loss: 0.2935 - accuracy: 0.8761 - val_loss: 0.2357 - val_accuracy: 0.9090\n",
            "Epoch 38/500\n",
            "106/105 [==============================] - 22s 210ms/step - loss: 0.2853 - accuracy: 0.8770 - val_loss: 0.2235 - val_accuracy: 0.9116\n",
            "Epoch 39/500\n",
            "106/105 [==============================] - 22s 209ms/step - loss: 0.2872 - accuracy: 0.8805 - val_loss: 0.2225 - val_accuracy: 0.9124\n",
            "Epoch 40/500\n",
            "106/105 [==============================] - 22s 209ms/step - loss: 0.2810 - accuracy: 0.8791 - val_loss: 0.3540 - val_accuracy: 0.8214\n",
            "Epoch 41/500\n",
            "106/105 [==============================] - 22s 209ms/step - loss: 0.2841 - accuracy: 0.8795 - val_loss: 0.2172 - val_accuracy: 0.9060\n",
            "Epoch 42/500\n",
            "106/105 [==============================] - 22s 208ms/step - loss: 0.2754 - accuracy: 0.8841 - val_loss: 0.2038 - val_accuracy: 0.9184\n",
            "Epoch 43/500\n",
            "106/105 [==============================] - 22s 207ms/step - loss: 0.2736 - accuracy: 0.8852 - val_loss: 0.2139 - val_accuracy: 0.9154\n",
            "Epoch 44/500\n",
            "106/105 [==============================] - 22s 207ms/step - loss: 0.2735 - accuracy: 0.8870 - val_loss: 0.1991 - val_accuracy: 0.9203\n",
            "Epoch 45/500\n",
            "106/105 [==============================] - 22s 209ms/step - loss: 0.2686 - accuracy: 0.8881 - val_loss: 0.2854 - val_accuracy: 0.8931\n",
            "Epoch 46/500\n",
            "106/105 [==============================] - 22s 207ms/step - loss: 0.2676 - accuracy: 0.8873 - val_loss: 0.2147 - val_accuracy: 0.9169\n",
            "Epoch 47/500\n",
            "106/105 [==============================] - 22s 207ms/step - loss: 0.2674 - accuracy: 0.8878 - val_loss: 0.2081 - val_accuracy: 0.9162\n",
            "Epoch 48/500\n",
            "106/105 [==============================] - 22s 209ms/step - loss: 0.2655 - accuracy: 0.8880 - val_loss: 0.2009 - val_accuracy: 0.9233\n",
            "Epoch 49/500\n",
            "106/105 [==============================] - 22s 211ms/step - loss: 0.2587 - accuracy: 0.8949 - val_loss: 0.2614 - val_accuracy: 0.9079\n",
            "Epoch 50/500\n",
            "106/105 [==============================] - 22s 208ms/step - loss: 0.2544 - accuracy: 0.8944 - val_loss: 0.2288 - val_accuracy: 0.9097\n",
            "Epoch 51/500\n",
            "106/105 [==============================] - 22s 209ms/step - loss: 0.2538 - accuracy: 0.8949 - val_loss: 0.2363 - val_accuracy: 0.8973\n",
            "Epoch 52/500\n",
            "106/105 [==============================] - 22s 209ms/step - loss: 0.2521 - accuracy: 0.8954 - val_loss: 0.2074 - val_accuracy: 0.9188\n",
            "Epoch 53/500\n",
            "106/105 [==============================] - 22s 209ms/step - loss: 0.2480 - accuracy: 0.8984 - val_loss: 0.1861 - val_accuracy: 0.9290\n",
            "Epoch 54/500\n",
            "106/105 [==============================] - 22s 210ms/step - loss: 0.2518 - accuracy: 0.8960 - val_loss: 0.1837 - val_accuracy: 0.9226\n",
            "Epoch 55/500\n",
            "106/105 [==============================] - 22s 211ms/step - loss: 0.2442 - accuracy: 0.8993 - val_loss: 0.1991 - val_accuracy: 0.9199\n",
            "Epoch 56/500\n",
            "106/105 [==============================] - 22s 211ms/step - loss: 0.2469 - accuracy: 0.9004 - val_loss: 0.1890 - val_accuracy: 0.9248\n",
            "Epoch 57/500\n",
            "106/105 [==============================] - 22s 209ms/step - loss: 0.2451 - accuracy: 0.8966 - val_loss: 0.2342 - val_accuracy: 0.9022\n",
            "Epoch 58/500\n",
            "106/105 [==============================] - 22s 210ms/step - loss: 0.2524 - accuracy: 0.8940 - val_loss: 0.1854 - val_accuracy: 0.9241\n",
            "Epoch 59/500\n",
            "106/105 [==============================] - 22s 208ms/step - loss: 0.2464 - accuracy: 0.8949 - val_loss: 0.1834 - val_accuracy: 0.9230\n",
            "Epoch 60/500\n",
            "106/105 [==============================] - 22s 206ms/step - loss: 0.2425 - accuracy: 0.9009 - val_loss: 0.1943 - val_accuracy: 0.9226\n",
            "Epoch 61/500\n",
            "106/105 [==============================] - 22s 205ms/step - loss: 0.2418 - accuracy: 0.9008 - val_loss: 0.1857 - val_accuracy: 0.9248\n",
            "Epoch 62/500\n",
            "106/105 [==============================] - 22s 206ms/step - loss: 0.2403 - accuracy: 0.9016 - val_loss: 0.1899 - val_accuracy: 0.9211\n",
            "Epoch 63/500\n",
            "106/105 [==============================] - 22s 209ms/step - loss: 0.2448 - accuracy: 0.8994 - val_loss: 0.1859 - val_accuracy: 0.9222\n",
            "Epoch 64/500\n",
            "106/105 [==============================] - 22s 208ms/step - loss: 0.2368 - accuracy: 0.9030 - val_loss: 0.1873 - val_accuracy: 0.9237\n",
            "Epoch 65/500\n",
            "106/105 [==============================] - 22s 208ms/step - loss: 0.2430 - accuracy: 0.8984 - val_loss: 0.1857 - val_accuracy: 0.9275\n",
            "Epoch 66/500\n",
            "106/105 [==============================] - 22s 210ms/step - loss: 0.2283 - accuracy: 0.9053 - val_loss: 0.1926 - val_accuracy: 0.9248\n",
            "Epoch 67/500\n",
            "106/105 [==============================] - 22s 207ms/step - loss: 0.2348 - accuracy: 0.9062 - val_loss: 0.2083 - val_accuracy: 0.9199\n",
            "Epoch 68/500\n",
            "106/105 [==============================] - 22s 209ms/step - loss: 0.2386 - accuracy: 0.9030 - val_loss: 0.1916 - val_accuracy: 0.9215\n",
            "Epoch 69/500\n",
            "106/105 [==============================] - 22s 209ms/step - loss: 0.2375 - accuracy: 0.9021 - val_loss: 0.2394 - val_accuracy: 0.9162\n",
            "Epoch 70/500\n",
            "106/105 [==============================] - 22s 210ms/step - loss: 0.2319 - accuracy: 0.9056 - val_loss: 0.1986 - val_accuracy: 0.9184\n",
            "Epoch 71/500\n",
            "106/105 [==============================] - 22s 208ms/step - loss: 0.2218 - accuracy: 0.9104 - val_loss: 0.1886 - val_accuracy: 0.9237\n",
            "Epoch 72/500\n",
            "106/105 [==============================] - 22s 211ms/step - loss: 0.2277 - accuracy: 0.9096 - val_loss: 0.1781 - val_accuracy: 0.9298\n",
            "Epoch 73/500\n",
            "106/105 [==============================] - 22s 206ms/step - loss: 0.2227 - accuracy: 0.9076 - val_loss: 0.2085 - val_accuracy: 0.9211\n",
            "Epoch 74/500\n",
            "106/105 [==============================] - 22s 208ms/step - loss: 0.2151 - accuracy: 0.9119 - val_loss: 0.1721 - val_accuracy: 0.9313\n",
            "Epoch 75/500\n",
            "106/105 [==============================] - 22s 209ms/step - loss: 0.2222 - accuracy: 0.9103 - val_loss: 0.1949 - val_accuracy: 0.9230\n",
            "Epoch 76/500\n",
            "106/105 [==============================] - 22s 211ms/step - loss: 0.2260 - accuracy: 0.9046 - val_loss: 0.2146 - val_accuracy: 0.9139\n",
            "Epoch 77/500\n",
            "106/105 [==============================] - 23s 213ms/step - loss: 0.2201 - accuracy: 0.9125 - val_loss: 0.2208 - val_accuracy: 0.9181\n",
            "Epoch 78/500\n",
            "106/105 [==============================] - 22s 211ms/step - loss: 0.2144 - accuracy: 0.9145 - val_loss: 0.1753 - val_accuracy: 0.9256\n",
            "Epoch 79/500\n",
            "106/105 [==============================] - 22s 208ms/step - loss: 0.2186 - accuracy: 0.9102 - val_loss: 0.1667 - val_accuracy: 0.9264\n",
            "Epoch 80/500\n",
            "106/105 [==============================] - 22s 207ms/step - loss: 0.2145 - accuracy: 0.9124 - val_loss: 0.1669 - val_accuracy: 0.9320\n",
            "Epoch 81/500\n",
            "106/105 [==============================] - 22s 208ms/step - loss: 0.2212 - accuracy: 0.9125 - val_loss: 0.1657 - val_accuracy: 0.9358\n",
            "Epoch 82/500\n",
            "106/105 [==============================] - 22s 210ms/step - loss: 0.2129 - accuracy: 0.9112 - val_loss: 0.1674 - val_accuracy: 0.9320\n",
            "Epoch 83/500\n",
            "106/105 [==============================] - 22s 208ms/step - loss: 0.2183 - accuracy: 0.9103 - val_loss: 0.2258 - val_accuracy: 0.9162\n",
            "Epoch 84/500\n",
            "106/105 [==============================] - 22s 208ms/step - loss: 0.2195 - accuracy: 0.9107 - val_loss: 0.1709 - val_accuracy: 0.9275\n",
            "Epoch 85/500\n",
            "106/105 [==============================] - 22s 209ms/step - loss: 0.2160 - accuracy: 0.9110 - val_loss: 0.1656 - val_accuracy: 0.9324\n",
            "Epoch 86/500\n",
            "106/105 [==============================] - 22s 210ms/step - loss: 0.2149 - accuracy: 0.9139 - val_loss: 0.1611 - val_accuracy: 0.9313\n",
            "Epoch 87/500\n",
            "106/105 [==============================] - 22s 208ms/step - loss: 0.2137 - accuracy: 0.9150 - val_loss: 0.1723 - val_accuracy: 0.9271\n",
            "Epoch 88/500\n",
            "106/105 [==============================] - 22s 210ms/step - loss: 0.2134 - accuracy: 0.9121 - val_loss: 0.1876 - val_accuracy: 0.9279\n",
            "Epoch 89/500\n",
            "106/105 [==============================] - 22s 211ms/step - loss: 0.2160 - accuracy: 0.9099 - val_loss: 0.1930 - val_accuracy: 0.9264\n",
            "Epoch 90/500\n",
            "106/105 [==============================] - 22s 211ms/step - loss: 0.2109 - accuracy: 0.9149 - val_loss: 0.1726 - val_accuracy: 0.9301\n",
            "Epoch 91/500\n",
            "106/105 [==============================] - 23s 215ms/step - loss: 0.2096 - accuracy: 0.9137 - val_loss: 0.2204 - val_accuracy: 0.9135\n",
            "Epoch 92/500\n",
            "106/105 [==============================] - 22s 212ms/step - loss: 0.2089 - accuracy: 0.9132 - val_loss: 0.1914 - val_accuracy: 0.9241\n",
            "Epoch 93/500\n",
            "106/105 [==============================] - 22s 210ms/step - loss: 0.2163 - accuracy: 0.9111 - val_loss: 0.1668 - val_accuracy: 0.9298\n",
            "Epoch 94/500\n",
            "106/105 [==============================] - 22s 209ms/step - loss: 0.2069 - accuracy: 0.9187 - val_loss: 0.1762 - val_accuracy: 0.9313\n",
            "Epoch 95/500\n",
            "106/105 [==============================] - 22s 211ms/step - loss: 0.2159 - accuracy: 0.9124 - val_loss: 0.1586 - val_accuracy: 0.9316\n",
            "Epoch 96/500\n",
            "106/105 [==============================] - 22s 209ms/step - loss: 0.2136 - accuracy: 0.9115 - val_loss: 0.1724 - val_accuracy: 0.9290\n",
            "Epoch 97/500\n",
            "106/105 [==============================] - 22s 210ms/step - loss: 0.2139 - accuracy: 0.9122 - val_loss: 0.1886 - val_accuracy: 0.9298\n",
            "Epoch 98/500\n",
            "106/105 [==============================] - 22s 209ms/step - loss: 0.2109 - accuracy: 0.9136 - val_loss: 0.1966 - val_accuracy: 0.9252\n",
            "Epoch 99/500\n",
            "106/105 [==============================] - 22s 210ms/step - loss: 0.2056 - accuracy: 0.9174 - val_loss: 0.2097 - val_accuracy: 0.9230\n",
            "Epoch 100/500\n",
            "106/105 [==============================] - 22s 209ms/step - loss: 0.2138 - accuracy: 0.9130 - val_loss: 0.1730 - val_accuracy: 0.9294\n",
            "Epoch 101/500\n",
            "106/105 [==============================] - 22s 206ms/step - loss: 0.2118 - accuracy: 0.9153 - val_loss: 0.2232 - val_accuracy: 0.9233\n",
            "Epoch 102/500\n",
            "106/105 [==============================] - 22s 206ms/step - loss: 0.2059 - accuracy: 0.9136 - val_loss: 0.1895 - val_accuracy: 0.9267\n",
            "Epoch 103/500\n",
            "106/105 [==============================] - 22s 208ms/step - loss: 0.2039 - accuracy: 0.9196 - val_loss: 0.1643 - val_accuracy: 0.9313\n",
            "Epoch 104/500\n",
            "106/105 [==============================] - 22s 205ms/step - loss: 0.2097 - accuracy: 0.9119 - val_loss: 0.1694 - val_accuracy: 0.9324\n",
            "Epoch 105/500\n",
            "106/105 [==============================] - 22s 208ms/step - loss: 0.2075 - accuracy: 0.9154 - val_loss: 0.1729 - val_accuracy: 0.9335\n",
            "Epoch 106/500\n",
            "106/105 [==============================] - 22s 205ms/step - loss: 0.2025 - accuracy: 0.9199 - val_loss: 0.1963 - val_accuracy: 0.9294\n",
            "Epoch 107/500\n",
            "106/105 [==============================] - 22s 206ms/step - loss: 0.2076 - accuracy: 0.9155 - val_loss: 0.1593 - val_accuracy: 0.9343\n",
            "Epoch 108/500\n",
            "106/105 [==============================] - 22s 206ms/step - loss: 0.2002 - accuracy: 0.9202 - val_loss: 0.1599 - val_accuracy: 0.9358\n",
            "Epoch 109/500\n",
            "106/105 [==============================] - 22s 206ms/step - loss: 0.1961 - accuracy: 0.9209 - val_loss: 0.1652 - val_accuracy: 0.9358\n",
            "Epoch 110/500\n",
            "106/105 [==============================] - 22s 207ms/step - loss: 0.2020 - accuracy: 0.9175 - val_loss: 0.1594 - val_accuracy: 0.9369\n",
            "Epoch 111/500\n",
            "106/105 [==============================] - 22s 205ms/step - loss: 0.2049 - accuracy: 0.9166 - val_loss: 0.1587 - val_accuracy: 0.9332\n",
            "Epoch 112/500\n",
            "106/105 [==============================] - 22s 205ms/step - loss: 0.1962 - accuracy: 0.9205 - val_loss: 0.1629 - val_accuracy: 0.9343\n",
            "Epoch 113/500\n",
            "106/105 [==============================] - 22s 205ms/step - loss: 0.2015 - accuracy: 0.9202 - val_loss: 0.1645 - val_accuracy: 0.9347\n",
            "Epoch 114/500\n",
            "106/105 [==============================] - 22s 208ms/step - loss: 0.1944 - accuracy: 0.9218 - val_loss: 0.1732 - val_accuracy: 0.9347\n",
            "Epoch 115/500\n",
            "106/105 [==============================] - 22s 205ms/step - loss: 0.2005 - accuracy: 0.9185 - val_loss: 0.1719 - val_accuracy: 0.9316\n",
            "Epoch 116/500\n",
            "106/105 [==============================] - 22s 208ms/step - loss: 0.2020 - accuracy: 0.9181 - val_loss: 0.1605 - val_accuracy: 0.9354\n",
            "Epoch 117/500\n",
            "106/105 [==============================] - 22s 209ms/step - loss: 0.1971 - accuracy: 0.9192 - val_loss: 0.1779 - val_accuracy: 0.9358\n",
            "Epoch 118/500\n",
            "106/105 [==============================] - 22s 207ms/step - loss: 0.1992 - accuracy: 0.9191 - val_loss: 0.1721 - val_accuracy: 0.9335\n",
            "Epoch 119/500\n",
            "106/105 [==============================] - 22s 210ms/step - loss: 0.1923 - accuracy: 0.9200 - val_loss: 0.1599 - val_accuracy: 0.9362\n",
            "Epoch 120/500\n",
            "106/105 [==============================] - 22s 208ms/step - loss: 0.1963 - accuracy: 0.9199 - val_loss: 0.1632 - val_accuracy: 0.9350\n",
            "Epoch 121/500\n",
            "106/105 [==============================] - 22s 210ms/step - loss: 0.1989 - accuracy: 0.9195 - val_loss: 0.1575 - val_accuracy: 0.9350\n",
            "Epoch 122/500\n",
            "106/105 [==============================] - 22s 209ms/step - loss: 0.1910 - accuracy: 0.9235 - val_loss: 0.1723 - val_accuracy: 0.9347\n",
            "Epoch 123/500\n",
            "106/105 [==============================] - 22s 209ms/step - loss: 0.2007 - accuracy: 0.9174 - val_loss: 0.1609 - val_accuracy: 0.9354\n",
            "Epoch 124/500\n",
            "106/105 [==============================] - 22s 210ms/step - loss: 0.1960 - accuracy: 0.9205 - val_loss: 0.1709 - val_accuracy: 0.9335\n",
            "Epoch 125/500\n",
            "106/105 [==============================] - 23s 213ms/step - loss: 0.1949 - accuracy: 0.9205 - val_loss: 0.1599 - val_accuracy: 0.9369\n",
            "Epoch 126/500\n",
            "106/105 [==============================] - 22s 209ms/step - loss: 0.1990 - accuracy: 0.9212 - val_loss: 0.1563 - val_accuracy: 0.9347\n",
            "Epoch 127/500\n",
            "106/105 [==============================] - 22s 210ms/step - loss: 0.1906 - accuracy: 0.9243 - val_loss: 0.1601 - val_accuracy: 0.9343\n",
            "Epoch 128/500\n",
            "106/105 [==============================] - 22s 210ms/step - loss: 0.1929 - accuracy: 0.9223 - val_loss: 0.1544 - val_accuracy: 0.9350\n",
            "Epoch 129/500\n",
            "106/105 [==============================] - 22s 210ms/step - loss: 0.1925 - accuracy: 0.9241 - val_loss: 0.1569 - val_accuracy: 0.9366\n",
            "Epoch 130/500\n",
            "106/105 [==============================] - 22s 209ms/step - loss: 0.1987 - accuracy: 0.9186 - val_loss: 0.1762 - val_accuracy: 0.9354\n",
            "Epoch 131/500\n",
            "106/105 [==============================] - 22s 208ms/step - loss: 0.1958 - accuracy: 0.9223 - val_loss: 0.1607 - val_accuracy: 0.9366\n",
            "Epoch 132/500\n",
            "106/105 [==============================] - 22s 210ms/step - loss: 0.1952 - accuracy: 0.9212 - val_loss: 0.1624 - val_accuracy: 0.9362\n",
            "Epoch 133/500\n",
            "106/105 [==============================] - 22s 211ms/step - loss: 0.1922 - accuracy: 0.9252 - val_loss: 0.1561 - val_accuracy: 0.9350\n",
            "Epoch 134/500\n",
            "106/105 [==============================] - 22s 207ms/step - loss: 0.1949 - accuracy: 0.9211 - val_loss: 0.1663 - val_accuracy: 0.9335\n",
            "Epoch 135/500\n",
            "106/105 [==============================] - 22s 208ms/step - loss: 0.1933 - accuracy: 0.9236 - val_loss: 0.1583 - val_accuracy: 0.9354\n",
            "Epoch 136/500\n",
            "106/105 [==============================] - 22s 207ms/step - loss: 0.1933 - accuracy: 0.9199 - val_loss: 0.1609 - val_accuracy: 0.9328\n",
            "Epoch 137/500\n",
            "106/105 [==============================] - 22s 207ms/step - loss: 0.1894 - accuracy: 0.9223 - val_loss: 0.1530 - val_accuracy: 0.9377\n",
            "Epoch 138/500\n",
            "106/105 [==============================] - 22s 206ms/step - loss: 0.1976 - accuracy: 0.9192 - val_loss: 0.1519 - val_accuracy: 0.9384\n",
            "Epoch 139/500\n",
            "106/105 [==============================] - 22s 207ms/step - loss: 0.1929 - accuracy: 0.9234 - val_loss: 0.1741 - val_accuracy: 0.9328\n",
            "Epoch 140/500\n",
            "106/105 [==============================] - 22s 205ms/step - loss: 0.2004 - accuracy: 0.9200 - val_loss: 0.1646 - val_accuracy: 0.9328\n",
            "Epoch 141/500\n",
            "106/105 [==============================] - 22s 205ms/step - loss: 0.1965 - accuracy: 0.9209 - val_loss: 0.1695 - val_accuracy: 0.9358\n",
            "Epoch 142/500\n",
            "106/105 [==============================] - 22s 206ms/step - loss: 0.1896 - accuracy: 0.9214 - val_loss: 0.1552 - val_accuracy: 0.9358\n",
            "Epoch 143/500\n",
            "106/105 [==============================] - 22s 208ms/step - loss: 0.1961 - accuracy: 0.9205 - val_loss: 0.1647 - val_accuracy: 0.9343\n",
            "Epoch 144/500\n",
            "106/105 [==============================] - 22s 207ms/step - loss: 0.1908 - accuracy: 0.9223 - val_loss: 0.1569 - val_accuracy: 0.9335\n",
            "Epoch 145/500\n",
            "106/105 [==============================] - 22s 205ms/step - loss: 0.1906 - accuracy: 0.9231 - val_loss: 0.1524 - val_accuracy: 0.9392\n",
            "Epoch 146/500\n",
            "106/105 [==============================] - 22s 207ms/step - loss: 0.1912 - accuracy: 0.9225 - val_loss: 0.1515 - val_accuracy: 0.9347\n",
            "Epoch 147/500\n",
            "106/105 [==============================] - 22s 210ms/step - loss: 0.1973 - accuracy: 0.9217 - val_loss: 0.1732 - val_accuracy: 0.9313\n",
            "Epoch 148/500\n",
            "106/105 [==============================] - 22s 206ms/step - loss: 0.1867 - accuracy: 0.9253 - val_loss: 0.1576 - val_accuracy: 0.9354\n",
            "Epoch 149/500\n",
            "106/105 [==============================] - 22s 207ms/step - loss: 0.1877 - accuracy: 0.9238 - val_loss: 0.1677 - val_accuracy: 0.9347\n",
            "Epoch 150/500\n",
            "106/105 [==============================] - 22s 209ms/step - loss: 0.1955 - accuracy: 0.9214 - val_loss: 0.1564 - val_accuracy: 0.9335\n",
            "Epoch 151/500\n",
            "106/105 [==============================] - 22s 208ms/step - loss: 0.1907 - accuracy: 0.9233 - val_loss: 0.1527 - val_accuracy: 0.9366\n",
            "Epoch 152/500\n",
            "106/105 [==============================] - 22s 210ms/step - loss: 0.1961 - accuracy: 0.9207 - val_loss: 0.1521 - val_accuracy: 0.9362\n",
            "Epoch 153/500\n",
            "106/105 [==============================] - 22s 208ms/step - loss: 0.1945 - accuracy: 0.9225 - val_loss: 0.1545 - val_accuracy: 0.9347\n",
            "Epoch 154/500\n",
            "106/105 [==============================] - 22s 212ms/step - loss: 0.1973 - accuracy: 0.9199 - val_loss: 0.1559 - val_accuracy: 0.9335\n",
            "Epoch 155/500\n",
            "106/105 [==============================] - 22s 211ms/step - loss: 0.1958 - accuracy: 0.9221 - val_loss: 0.1508 - val_accuracy: 0.9373\n",
            "Epoch 156/500\n",
            "106/105 [==============================] - 22s 210ms/step - loss: 0.1893 - accuracy: 0.9225 - val_loss: 0.1524 - val_accuracy: 0.9369\n",
            "Epoch 157/500\n",
            "106/105 [==============================] - 22s 211ms/step - loss: 0.1939 - accuracy: 0.9214 - val_loss: 0.1578 - val_accuracy: 0.9354\n",
            "Epoch 158/500\n",
            "106/105 [==============================] - 22s 212ms/step - loss: 0.1933 - accuracy: 0.9216 - val_loss: 0.1651 - val_accuracy: 0.9347\n",
            "Epoch 159/500\n",
            "106/105 [==============================] - 22s 210ms/step - loss: 0.1968 - accuracy: 0.9221 - val_loss: 0.1711 - val_accuracy: 0.9347\n",
            "Epoch 160/500\n",
            "106/105 [==============================] - 22s 212ms/step - loss: 0.1902 - accuracy: 0.9231 - val_loss: 0.1537 - val_accuracy: 0.9373\n",
            "Epoch 161/500\n",
            "106/105 [==============================] - 23s 214ms/step - loss: 0.1940 - accuracy: 0.9205 - val_loss: 0.1625 - val_accuracy: 0.9354\n",
            "Epoch 162/500\n",
            "106/105 [==============================] - 23s 213ms/step - loss: 0.1940 - accuracy: 0.9189 - val_loss: 0.1513 - val_accuracy: 0.9350\n",
            "Epoch 163/500\n",
            "106/105 [==============================] - 23s 213ms/step - loss: 0.1962 - accuracy: 0.9225 - val_loss: 0.1527 - val_accuracy: 0.9332\n",
            "Epoch 164/500\n",
            "106/105 [==============================] - 22s 208ms/step - loss: 0.1925 - accuracy: 0.9229 - val_loss: 0.1586 - val_accuracy: 0.9358\n",
            "Epoch 165/500\n",
            "106/105 [==============================] - 22s 209ms/step - loss: 0.1908 - accuracy: 0.9204 - val_loss: 0.1483 - val_accuracy: 0.9377\n",
            "Epoch 166/500\n",
            "106/105 [==============================] - 22s 209ms/step - loss: 0.1949 - accuracy: 0.9226 - val_loss: 0.1605 - val_accuracy: 0.9366\n",
            "Epoch 167/500\n",
            "106/105 [==============================] - 23s 216ms/step - loss: 0.1951 - accuracy: 0.9226 - val_loss: 0.1528 - val_accuracy: 0.9381\n",
            "Epoch 168/500\n",
            "106/105 [==============================] - 23s 219ms/step - loss: 0.1900 - accuracy: 0.9235 - val_loss: 0.1595 - val_accuracy: 0.9343\n",
            "Epoch 169/500\n",
            "106/105 [==============================] - 23s 214ms/step - loss: 0.1950 - accuracy: 0.9227 - val_loss: 0.1538 - val_accuracy: 0.9373\n",
            "Epoch 170/500\n",
            "106/105 [==============================] - 22s 209ms/step - loss: 0.1935 - accuracy: 0.9224 - val_loss: 0.1554 - val_accuracy: 0.9377\n",
            "Epoch 171/500\n",
            "106/105 [==============================] - 22s 212ms/step - loss: 0.1918 - accuracy: 0.9210 - val_loss: 0.1496 - val_accuracy: 0.9350\n",
            "Epoch 172/500\n",
            "106/105 [==============================] - 23s 213ms/step - loss: 0.1931 - accuracy: 0.9189 - val_loss: 0.1538 - val_accuracy: 0.9373\n",
            "Epoch 173/500\n",
            "106/105 [==============================] - 22s 209ms/step - loss: 0.1929 - accuracy: 0.9213 - val_loss: 0.1532 - val_accuracy: 0.9369\n",
            "Epoch 174/500\n",
            "106/105 [==============================] - 22s 211ms/step - loss: 0.1847 - accuracy: 0.9274 - val_loss: 0.1544 - val_accuracy: 0.9343\n",
            "Epoch 175/500\n",
            "106/105 [==============================] - 22s 210ms/step - loss: 0.1916 - accuracy: 0.9205 - val_loss: 0.1475 - val_accuracy: 0.9358\n",
            "Epoch 176/500\n",
            "106/105 [==============================] - 22s 209ms/step - loss: 0.1872 - accuracy: 0.9233 - val_loss: 0.1588 - val_accuracy: 0.9347\n",
            "Epoch 177/500\n",
            "106/105 [==============================] - 23s 212ms/step - loss: 0.1859 - accuracy: 0.9228 - val_loss: 0.1584 - val_accuracy: 0.9354\n",
            "Epoch 178/500\n",
            "106/105 [==============================] - 23s 214ms/step - loss: 0.1978 - accuracy: 0.9177 - val_loss: 0.1500 - val_accuracy: 0.9369\n",
            "Epoch 179/500\n",
            "106/105 [==============================] - 23s 216ms/step - loss: 0.1834 - accuracy: 0.9296 - val_loss: 0.1461 - val_accuracy: 0.9366\n",
            "Epoch 180/500\n",
            "106/105 [==============================] - 23s 218ms/step - loss: 0.1941 - accuracy: 0.9231 - val_loss: 0.1478 - val_accuracy: 0.9392\n",
            "Epoch 181/500\n",
            "106/105 [==============================] - 23s 217ms/step - loss: 0.1888 - accuracy: 0.9228 - val_loss: 0.1493 - val_accuracy: 0.9354\n",
            "Epoch 182/500\n",
            "106/105 [==============================] - 23s 218ms/step - loss: 0.1867 - accuracy: 0.9249 - val_loss: 0.1615 - val_accuracy: 0.9358\n",
            "Epoch 183/500\n",
            "106/105 [==============================] - 23s 213ms/step - loss: 0.1884 - accuracy: 0.9245 - val_loss: 0.1565 - val_accuracy: 0.9369\n",
            "Epoch 184/500\n",
            "106/105 [==============================] - 22s 211ms/step - loss: 0.1855 - accuracy: 0.9288 - val_loss: 0.1600 - val_accuracy: 0.9347\n",
            "Epoch 185/500\n",
            "106/105 [==============================] - 22s 211ms/step - loss: 0.1855 - accuracy: 0.9256 - val_loss: 0.1468 - val_accuracy: 0.9403\n",
            "Epoch 186/500\n",
            "106/105 [==============================] - 22s 211ms/step - loss: 0.1859 - accuracy: 0.9250 - val_loss: 0.1518 - val_accuracy: 0.9388\n",
            "Epoch 187/500\n",
            "106/105 [==============================] - 22s 208ms/step - loss: 0.1937 - accuracy: 0.9222 - val_loss: 0.1461 - val_accuracy: 0.9407\n",
            "Epoch 188/500\n",
            "106/105 [==============================] - 22s 209ms/step - loss: 0.1913 - accuracy: 0.9254 - val_loss: 0.1525 - val_accuracy: 0.9362\n",
            "Epoch 189/500\n",
            "106/105 [==============================] - 22s 209ms/step - loss: 0.1867 - accuracy: 0.9255 - val_loss: 0.1513 - val_accuracy: 0.9384\n",
            "Epoch 190/500\n",
            "106/105 [==============================] - 22s 207ms/step - loss: 0.1890 - accuracy: 0.9240 - val_loss: 0.1475 - val_accuracy: 0.9381\n",
            "Epoch 191/500\n",
            "106/105 [==============================] - 22s 205ms/step - loss: 0.1897 - accuracy: 0.9244 - val_loss: 0.1521 - val_accuracy: 0.9373\n",
            "Epoch 192/500\n",
            "106/105 [==============================] - 22s 204ms/step - loss: 0.1843 - accuracy: 0.9244 - val_loss: 0.1532 - val_accuracy: 0.9358\n",
            "Epoch 193/500\n",
            "106/105 [==============================] - 22s 206ms/step - loss: 0.1900 - accuracy: 0.9231 - val_loss: 0.1515 - val_accuracy: 0.9369\n",
            "Epoch 194/500\n",
            "106/105 [==============================] - 22s 204ms/step - loss: 0.1921 - accuracy: 0.9217 - val_loss: 0.1529 - val_accuracy: 0.9384\n",
            "Epoch 195/500\n",
            "106/105 [==============================] - 22s 203ms/step - loss: 0.1910 - accuracy: 0.9238 - val_loss: 0.1557 - val_accuracy: 0.9369\n",
            "Epoch 196/500\n",
            "106/105 [==============================] - 21s 202ms/step - loss: 0.1857 - accuracy: 0.9278 - val_loss: 0.1501 - val_accuracy: 0.9373\n",
            "Epoch 197/500\n",
            "106/105 [==============================] - 22s 203ms/step - loss: 0.1877 - accuracy: 0.9235 - val_loss: 0.1492 - val_accuracy: 0.9384\n",
            "Epoch 198/500\n",
            "106/105 [==============================] - 21s 202ms/step - loss: 0.1868 - accuracy: 0.9260 - val_loss: 0.1464 - val_accuracy: 0.9400\n",
            "Epoch 199/500\n",
            "106/105 [==============================] - 21s 202ms/step - loss: 0.1882 - accuracy: 0.9257 - val_loss: 0.1507 - val_accuracy: 0.9373\n",
            "Epoch 200/500\n",
            "106/105 [==============================] - 21s 203ms/step - loss: 0.1899 - accuracy: 0.9233 - val_loss: 0.1462 - val_accuracy: 0.9381\n",
            "Epoch 201/500\n",
            "106/105 [==============================] - 22s 204ms/step - loss: 0.1879 - accuracy: 0.9238 - val_loss: 0.1483 - val_accuracy: 0.9369\n",
            "Epoch 202/500\n",
            "106/105 [==============================] - 21s 201ms/step - loss: 0.1917 - accuracy: 0.9214 - val_loss: 0.1486 - val_accuracy: 0.9377\n",
            "Epoch 203/500\n",
            "106/105 [==============================] - 22s 204ms/step - loss: 0.1888 - accuracy: 0.9238 - val_loss: 0.1507 - val_accuracy: 0.9377\n",
            "Epoch 204/500\n",
            "106/105 [==============================] - 21s 202ms/step - loss: 0.1906 - accuracy: 0.9206 - val_loss: 0.1496 - val_accuracy: 0.9381\n",
            "Epoch 205/500\n",
            "106/105 [==============================] - 21s 202ms/step - loss: 0.1828 - accuracy: 0.9273 - val_loss: 0.1484 - val_accuracy: 0.9377\n",
            "Epoch 206/500\n",
            "106/105 [==============================] - 22s 204ms/step - loss: 0.1794 - accuracy: 0.9245 - val_loss: 0.1474 - val_accuracy: 0.9388\n",
            "Epoch 207/500\n",
            "106/105 [==============================] - 21s 202ms/step - loss: 0.1853 - accuracy: 0.9244 - val_loss: 0.1515 - val_accuracy: 0.9381\n",
            "Epoch 208/500\n",
            "106/105 [==============================] - 21s 202ms/step - loss: 0.1836 - accuracy: 0.9243 - val_loss: 0.1519 - val_accuracy: 0.9381\n",
            "Epoch 209/500\n",
            "106/105 [==============================] - 21s 202ms/step - loss: 0.1830 - accuracy: 0.9253 - val_loss: 0.1496 - val_accuracy: 0.9377\n",
            "Epoch 210/500\n",
            "106/105 [==============================] - 21s 201ms/step - loss: 0.1901 - accuracy: 0.9207 - val_loss: 0.1451 - val_accuracy: 0.9403\n",
            "Epoch 211/500\n",
            "106/105 [==============================] - 21s 201ms/step - loss: 0.1863 - accuracy: 0.9274 - val_loss: 0.1552 - val_accuracy: 0.9384\n",
            "Epoch 212/500\n",
            "106/105 [==============================] - 21s 203ms/step - loss: 0.1828 - accuracy: 0.9262 - val_loss: 0.1492 - val_accuracy: 0.9369\n",
            "Epoch 213/500\n",
            "106/105 [==============================] - 21s 201ms/step - loss: 0.1875 - accuracy: 0.9260 - val_loss: 0.1515 - val_accuracy: 0.9369\n",
            "Epoch 214/500\n",
            "106/105 [==============================] - 21s 201ms/step - loss: 0.1830 - accuracy: 0.9257 - val_loss: 0.1513 - val_accuracy: 0.9373\n",
            "Epoch 215/500\n",
            "106/105 [==============================] - 21s 201ms/step - loss: 0.1918 - accuracy: 0.9226 - val_loss: 0.1507 - val_accuracy: 0.9358\n",
            "Epoch 216/500\n",
            "106/105 [==============================] - 21s 202ms/step - loss: 0.1879 - accuracy: 0.9222 - val_loss: 0.1464 - val_accuracy: 0.9407\n",
            "Epoch 217/500\n",
            "106/105 [==============================] - 21s 203ms/step - loss: 0.1838 - accuracy: 0.9262 - val_loss: 0.1472 - val_accuracy: 0.9381\n",
            "Epoch 218/500\n",
            "106/105 [==============================] - 21s 202ms/step - loss: 0.1846 - accuracy: 0.9260 - val_loss: 0.1467 - val_accuracy: 0.9403\n",
            "Epoch 219/500\n",
            "106/105 [==============================] - 21s 202ms/step - loss: 0.1899 - accuracy: 0.9222 - val_loss: 0.1474 - val_accuracy: 0.9388\n",
            "Epoch 220/500\n",
            "106/105 [==============================] - 22s 203ms/step - loss: 0.1871 - accuracy: 0.9242 - val_loss: 0.1497 - val_accuracy: 0.9381\n",
            "Epoch 221/500\n",
            "106/105 [==============================] - 21s 201ms/step - loss: 0.1857 - accuracy: 0.9222 - val_loss: 0.1492 - val_accuracy: 0.9377\n",
            "Epoch 222/500\n",
            "106/105 [==============================] - 21s 202ms/step - loss: 0.1936 - accuracy: 0.9223 - val_loss: 0.1483 - val_accuracy: 0.9403\n",
            "Epoch 223/500\n",
            "106/105 [==============================] - 22s 203ms/step - loss: 0.1829 - accuracy: 0.9265 - val_loss: 0.1493 - val_accuracy: 0.9369\n",
            "Epoch 224/500\n",
            "106/105 [==============================] - 21s 202ms/step - loss: 0.1833 - accuracy: 0.9274 - val_loss: 0.1495 - val_accuracy: 0.9388\n",
            "Epoch 225/500\n",
            "106/105 [==============================] - 21s 201ms/step - loss: 0.1844 - accuracy: 0.9251 - val_loss: 0.1487 - val_accuracy: 0.9403\n",
            "Epoch 226/500\n",
            "106/105 [==============================] - 21s 202ms/step - loss: 0.1831 - accuracy: 0.9244 - val_loss: 0.1585 - val_accuracy: 0.9366\n",
            "Epoch 227/500\n",
            "106/105 [==============================] - 21s 203ms/step - loss: 0.1830 - accuracy: 0.9281 - val_loss: 0.1505 - val_accuracy: 0.9384\n",
            "Epoch 228/500\n",
            "106/105 [==============================] - 21s 202ms/step - loss: 0.1839 - accuracy: 0.9264 - val_loss: 0.1443 - val_accuracy: 0.9422\n",
            "Epoch 229/500\n",
            "106/105 [==============================] - 21s 201ms/step - loss: 0.1860 - accuracy: 0.9231 - val_loss: 0.1460 - val_accuracy: 0.9418\n",
            "Epoch 230/500\n",
            "106/105 [==============================] - 21s 201ms/step - loss: 0.1837 - accuracy: 0.9262 - val_loss: 0.1463 - val_accuracy: 0.9373\n",
            "Epoch 231/500\n",
            "106/105 [==============================] - 22s 204ms/step - loss: 0.1872 - accuracy: 0.9247 - val_loss: 0.1460 - val_accuracy: 0.9392\n",
            "Epoch 232/500\n",
            "106/105 [==============================] - 22s 205ms/step - loss: 0.1840 - accuracy: 0.9255 - val_loss: 0.1484 - val_accuracy: 0.9377\n",
            "Epoch 233/500\n",
            "106/105 [==============================] - 22s 205ms/step - loss: 0.1832 - accuracy: 0.9303 - val_loss: 0.1501 - val_accuracy: 0.9388\n",
            "Epoch 234/500\n",
            "106/105 [==============================] - 22s 208ms/step - loss: 0.1862 - accuracy: 0.9244 - val_loss: 0.1590 - val_accuracy: 0.9354\n",
            "Epoch 235/500\n",
            "106/105 [==============================] - 22s 210ms/step - loss: 0.1868 - accuracy: 0.9207 - val_loss: 0.1494 - val_accuracy: 0.9373\n",
            "Epoch 236/500\n",
            "106/105 [==============================] - 22s 208ms/step - loss: 0.1869 - accuracy: 0.9245 - val_loss: 0.1506 - val_accuracy: 0.9369\n",
            "Epoch 237/500\n",
            "106/105 [==============================] - 22s 207ms/step - loss: 0.1891 - accuracy: 0.9227 - val_loss: 0.1470 - val_accuracy: 0.9396\n",
            "Epoch 238/500\n",
            "106/105 [==============================] - 22s 208ms/step - loss: 0.1842 - accuracy: 0.9271 - val_loss: 0.1476 - val_accuracy: 0.9377\n",
            "Epoch 239/500\n",
            "106/105 [==============================] - 22s 205ms/step - loss: 0.1880 - accuracy: 0.9240 - val_loss: 0.1495 - val_accuracy: 0.9388\n",
            "Epoch 240/500\n",
            "106/105 [==============================] - 22s 204ms/step - loss: 0.1825 - accuracy: 0.9273 - val_loss: 0.1456 - val_accuracy: 0.9396\n",
            "Epoch 241/500\n",
            "106/105 [==============================] - 21s 203ms/step - loss: 0.1859 - accuracy: 0.9244 - val_loss: 0.1466 - val_accuracy: 0.9400\n",
            "Epoch 242/500\n",
            "106/105 [==============================] - 22s 204ms/step - loss: 0.1885 - accuracy: 0.9241 - val_loss: 0.1466 - val_accuracy: 0.9407\n",
            "Epoch 243/500\n",
            "106/105 [==============================] - 21s 202ms/step - loss: 0.1911 - accuracy: 0.9233 - val_loss: 0.1489 - val_accuracy: 0.9384\n",
            "Epoch 244/500\n",
            "106/105 [==============================] - 21s 203ms/step - loss: 0.1847 - accuracy: 0.9243 - val_loss: 0.1460 - val_accuracy: 0.9384\n",
            "Epoch 245/500\n",
            "106/105 [==============================] - 21s 202ms/step - loss: 0.1852 - accuracy: 0.9277 - val_loss: 0.1485 - val_accuracy: 0.9384\n",
            "Epoch 246/500\n",
            "106/105 [==============================] - 22s 206ms/step - loss: 0.1855 - accuracy: 0.9258 - val_loss: 0.1469 - val_accuracy: 0.9384\n",
            "Epoch 247/500\n",
            "106/105 [==============================] - 21s 202ms/step - loss: 0.1848 - accuracy: 0.9272 - val_loss: 0.1484 - val_accuracy: 0.9366\n",
            "Epoch 248/500\n",
            "106/105 [==============================] - 22s 203ms/step - loss: 0.1803 - accuracy: 0.9292 - val_loss: 0.1462 - val_accuracy: 0.9411\n",
            "Epoch 249/500\n",
            "106/105 [==============================] - 21s 202ms/step - loss: 0.1883 - accuracy: 0.9256 - val_loss: 0.1559 - val_accuracy: 0.9369\n",
            "Epoch 250/500\n",
            "106/105 [==============================] - 21s 203ms/step - loss: 0.1880 - accuracy: 0.9249 - val_loss: 0.1463 - val_accuracy: 0.9392\n",
            "Epoch 251/500\n",
            "106/105 [==============================] - 21s 201ms/step - loss: 0.1856 - accuracy: 0.9251 - val_loss: 0.1487 - val_accuracy: 0.9373\n",
            "Epoch 252/500\n",
            "106/105 [==============================] - 21s 201ms/step - loss: 0.1812 - accuracy: 0.9280 - val_loss: 0.1454 - val_accuracy: 0.9411\n",
            "Epoch 253/500\n",
            "106/105 [==============================] - 22s 203ms/step - loss: 0.1875 - accuracy: 0.9227 - val_loss: 0.1472 - val_accuracy: 0.9369\n",
            "Epoch 254/500\n",
            "106/105 [==============================] - 21s 202ms/step - loss: 0.1902 - accuracy: 0.9218 - val_loss: 0.1494 - val_accuracy: 0.9388\n",
            "Epoch 255/500\n",
            "106/105 [==============================] - 21s 201ms/step - loss: 0.1832 - accuracy: 0.9247 - val_loss: 0.1462 - val_accuracy: 0.9396\n",
            "Epoch 256/500\n",
            "106/105 [==============================] - 21s 200ms/step - loss: 0.1898 - accuracy: 0.9220 - val_loss: 0.1444 - val_accuracy: 0.9407\n",
            "Epoch 257/500\n",
            "106/105 [==============================] - 21s 202ms/step - loss: 0.1845 - accuracy: 0.9231 - val_loss: 0.1459 - val_accuracy: 0.9392\n",
            "Epoch 258/500\n",
            "106/105 [==============================] - 21s 200ms/step - loss: 0.1908 - accuracy: 0.9257 - val_loss: 0.1489 - val_accuracy: 0.9381\n",
            "Epoch 259/500\n",
            "106/105 [==============================] - 21s 201ms/step - loss: 0.1887 - accuracy: 0.9285 - val_loss: 0.1466 - val_accuracy: 0.9377\n",
            "Epoch 260/500\n",
            "106/105 [==============================] - 21s 200ms/step - loss: 0.1841 - accuracy: 0.9252 - val_loss: 0.1462 - val_accuracy: 0.9396\n",
            "Epoch 261/500\n",
            "106/105 [==============================] - 22s 205ms/step - loss: 0.1871 - accuracy: 0.9263 - val_loss: 0.1465 - val_accuracy: 0.9373\n",
            "Epoch 262/500\n",
            "106/105 [==============================] - 21s 201ms/step - loss: 0.1886 - accuracy: 0.9207 - val_loss: 0.1455 - val_accuracy: 0.9407\n",
            "Epoch 263/500\n",
            "106/105 [==============================] - 21s 201ms/step - loss: 0.1839 - accuracy: 0.9306 - val_loss: 0.1450 - val_accuracy: 0.9411\n",
            "Epoch 264/500\n",
            "106/105 [==============================] - 21s 200ms/step - loss: 0.1845 - accuracy: 0.9252 - val_loss: 0.1488 - val_accuracy: 0.9381\n",
            "Epoch 265/500\n",
            "106/105 [==============================] - 21s 201ms/step - loss: 0.1878 - accuracy: 0.9239 - val_loss: 0.1469 - val_accuracy: 0.9377\n",
            "Epoch 266/500\n",
            "106/105 [==============================] - 21s 200ms/step - loss: 0.1864 - accuracy: 0.9256 - val_loss: 0.1465 - val_accuracy: 0.9377\n",
            "Epoch 267/500\n",
            "106/105 [==============================] - 21s 200ms/step - loss: 0.1844 - accuracy: 0.9276 - val_loss: 0.1501 - val_accuracy: 0.9377\n",
            "Epoch 268/500\n",
            "106/105 [==============================] - 21s 201ms/step - loss: 0.1866 - accuracy: 0.9250 - val_loss: 0.1457 - val_accuracy: 0.9403\n",
            "Epoch 269/500\n",
            "106/105 [==============================] - 21s 200ms/step - loss: 0.1804 - accuracy: 0.9269 - val_loss: 0.1456 - val_accuracy: 0.9381\n",
            "Epoch 270/500\n",
            "106/105 [==============================] - 21s 200ms/step - loss: 0.1825 - accuracy: 0.9262 - val_loss: 0.1454 - val_accuracy: 0.9392\n",
            "Epoch 271/500\n",
            "106/105 [==============================] - 21s 200ms/step - loss: 0.1853 - accuracy: 0.9239 - val_loss: 0.1459 - val_accuracy: 0.9384\n",
            "Epoch 272/500\n",
            "106/105 [==============================] - 21s 202ms/step - loss: 0.1860 - accuracy: 0.9250 - val_loss: 0.1472 - val_accuracy: 0.9403\n",
            "Epoch 273/500\n",
            "106/105 [==============================] - 21s 201ms/step - loss: 0.1820 - accuracy: 0.9288 - val_loss: 0.1467 - val_accuracy: 0.9392\n",
            "Epoch 274/500\n",
            "106/105 [==============================] - 21s 200ms/step - loss: 0.1848 - accuracy: 0.9256 - val_loss: 0.1459 - val_accuracy: 0.9396\n",
            "Epoch 275/500\n",
            "106/105 [==============================] - 21s 202ms/step - loss: 0.1844 - accuracy: 0.9248 - val_loss: 0.1474 - val_accuracy: 0.9396\n",
            "Epoch 276/500\n",
            "106/105 [==============================] - 21s 203ms/step - loss: 0.1839 - accuracy: 0.9275 - val_loss: 0.1457 - val_accuracy: 0.9388\n",
            "Epoch 277/500\n",
            "106/105 [==============================] - 21s 201ms/step - loss: 0.1845 - accuracy: 0.9294 - val_loss: 0.1446 - val_accuracy: 0.9403\n",
            "Epoch 278/500\n",
            "106/105 [==============================] - 21s 201ms/step - loss: 0.1833 - accuracy: 0.9248 - val_loss: 0.1484 - val_accuracy: 0.9377\n",
            "Epoch 279/500\n",
            "106/105 [==============================] - 21s 201ms/step - loss: 0.1854 - accuracy: 0.9260 - val_loss: 0.1435 - val_accuracy: 0.9422\n",
            "Epoch 280/500\n",
            "106/105 [==============================] - 21s 201ms/step - loss: 0.1823 - accuracy: 0.9245 - val_loss: 0.1471 - val_accuracy: 0.9377\n",
            "Epoch 281/500\n",
            "106/105 [==============================] - 21s 202ms/step - loss: 0.1872 - accuracy: 0.9229 - val_loss: 0.1485 - val_accuracy: 0.9366\n",
            "Epoch 282/500\n",
            "106/105 [==============================] - 21s 200ms/step - loss: 0.1844 - accuracy: 0.9251 - val_loss: 0.1486 - val_accuracy: 0.9373\n",
            "Epoch 283/500\n",
            "106/105 [==============================] - 21s 200ms/step - loss: 0.1857 - accuracy: 0.9256 - val_loss: 0.1456 - val_accuracy: 0.9388\n",
            "Epoch 284/500\n",
            "106/105 [==============================] - 21s 200ms/step - loss: 0.1845 - accuracy: 0.9287 - val_loss: 0.1452 - val_accuracy: 0.9426\n",
            "Epoch 285/500\n",
            "106/105 [==============================] - 21s 201ms/step - loss: 0.1779 - accuracy: 0.9287 - val_loss: 0.1457 - val_accuracy: 0.9388\n",
            "Epoch 286/500\n",
            "106/105 [==============================] - 21s 200ms/step - loss: 0.1857 - accuracy: 0.9251 - val_loss: 0.1503 - val_accuracy: 0.9388\n",
            "Epoch 287/500\n",
            "106/105 [==============================] - 21s 202ms/step - loss: 0.1802 - accuracy: 0.9268 - val_loss: 0.1502 - val_accuracy: 0.9373\n",
            "Epoch 288/500\n",
            "106/105 [==============================] - 21s 200ms/step - loss: 0.1850 - accuracy: 0.9252 - val_loss: 0.1442 - val_accuracy: 0.9407\n",
            "Epoch 289/500\n",
            "106/105 [==============================] - 21s 200ms/step - loss: 0.1813 - accuracy: 0.9265 - val_loss: 0.1461 - val_accuracy: 0.9392\n",
            "Epoch 290/500\n",
            "106/105 [==============================] - 22s 203ms/step - loss: 0.1854 - accuracy: 0.9242 - val_loss: 0.1463 - val_accuracy: 0.9400\n",
            "Epoch 291/500\n",
            "106/105 [==============================] - 22s 203ms/step - loss: 0.1837 - accuracy: 0.9264 - val_loss: 0.1450 - val_accuracy: 0.9407\n",
            "Epoch 292/500\n",
            "106/105 [==============================] - 21s 202ms/step - loss: 0.1824 - accuracy: 0.9269 - val_loss: 0.1466 - val_accuracy: 0.9396\n",
            "Epoch 293/500\n",
            "106/105 [==============================] - 21s 202ms/step - loss: 0.1819 - accuracy: 0.9264 - val_loss: 0.1445 - val_accuracy: 0.9407\n",
            "Epoch 294/500\n",
            "106/105 [==============================] - 22s 203ms/step - loss: 0.1803 - accuracy: 0.9258 - val_loss: 0.1599 - val_accuracy: 0.9369\n",
            "Epoch 295/500\n",
            "106/105 [==============================] - 22s 203ms/step - loss: 0.1891 - accuracy: 0.9240 - val_loss: 0.1448 - val_accuracy: 0.9411\n",
            "Epoch 296/500\n",
            "106/105 [==============================] - 22s 203ms/step - loss: 0.1791 - accuracy: 0.9291 - val_loss: 0.1554 - val_accuracy: 0.9369\n",
            "Epoch 297/500\n",
            "106/105 [==============================] - 22s 207ms/step - loss: 0.1888 - accuracy: 0.9252 - val_loss: 0.1489 - val_accuracy: 0.9373\n",
            "Epoch 298/500\n",
            "106/105 [==============================] - 22s 208ms/step - loss: 0.1805 - accuracy: 0.9271 - val_loss: 0.1426 - val_accuracy: 0.9426\n",
            "Epoch 299/500\n",
            "106/105 [==============================] - 22s 205ms/step - loss: 0.1859 - accuracy: 0.9252 - val_loss: 0.1454 - val_accuracy: 0.9400\n",
            "Epoch 300/500\n",
            "106/105 [==============================] - 22s 204ms/step - loss: 0.1793 - accuracy: 0.9277 - val_loss: 0.1498 - val_accuracy: 0.9373\n",
            "Epoch 301/500\n",
            "106/105 [==============================] - 22s 204ms/step - loss: 0.1840 - accuracy: 0.9268 - val_loss: 0.1479 - val_accuracy: 0.9377\n",
            "Epoch 302/500\n",
            "106/105 [==============================] - 22s 205ms/step - loss: 0.1855 - accuracy: 0.9244 - val_loss: 0.1468 - val_accuracy: 0.9369\n",
            "Epoch 303/500\n",
            "106/105 [==============================] - 22s 203ms/step - loss: 0.1810 - accuracy: 0.9259 - val_loss: 0.1454 - val_accuracy: 0.9388\n",
            "Epoch 304/500\n",
            "106/105 [==============================] - 22s 206ms/step - loss: 0.1799 - accuracy: 0.9285 - val_loss: 0.1448 - val_accuracy: 0.9384\n",
            "Epoch 305/500\n",
            "106/105 [==============================] - 22s 205ms/step - loss: 0.1870 - accuracy: 0.9251 - val_loss: 0.1526 - val_accuracy: 0.9354\n",
            "Epoch 306/500\n",
            "106/105 [==============================] - 22s 206ms/step - loss: 0.1836 - accuracy: 0.9256 - val_loss: 0.1452 - val_accuracy: 0.9396\n",
            "Epoch 307/500\n",
            "106/105 [==============================] - 22s 204ms/step - loss: 0.1816 - accuracy: 0.9277 - val_loss: 0.1461 - val_accuracy: 0.9388\n",
            "Epoch 308/500\n",
            "106/105 [==============================] - 22s 205ms/step - loss: 0.1839 - accuracy: 0.9255 - val_loss: 0.1482 - val_accuracy: 0.9392\n",
            "Epoch 309/500\n",
            "106/105 [==============================] - 22s 206ms/step - loss: 0.1844 - accuracy: 0.9220 - val_loss: 0.1502 - val_accuracy: 0.9377\n",
            "Epoch 310/500\n",
            "106/105 [==============================] - 22s 206ms/step - loss: 0.1779 - accuracy: 0.9276 - val_loss: 0.1442 - val_accuracy: 0.9415\n",
            "Epoch 311/500\n",
            "106/105 [==============================] - 22s 205ms/step - loss: 0.1796 - accuracy: 0.9283 - val_loss: 0.1452 - val_accuracy: 0.9388\n",
            "Epoch 312/500\n",
            "106/105 [==============================] - 22s 205ms/step - loss: 0.1790 - accuracy: 0.9270 - val_loss: 0.1456 - val_accuracy: 0.9388\n",
            "Epoch 313/500\n",
            "106/105 [==============================] - 22s 207ms/step - loss: 0.1901 - accuracy: 0.9221 - val_loss: 0.1442 - val_accuracy: 0.9381\n",
            "Epoch 314/500\n",
            "106/105 [==============================] - 22s 205ms/step - loss: 0.1831 - accuracy: 0.9245 - val_loss: 0.1461 - val_accuracy: 0.9381\n",
            "Epoch 315/500\n",
            "106/105 [==============================] - 22s 205ms/step - loss: 0.1819 - accuracy: 0.9252 - val_loss: 0.1511 - val_accuracy: 0.9362\n",
            "Epoch 316/500\n",
            "106/105 [==============================] - 22s 206ms/step - loss: 0.1836 - accuracy: 0.9258 - val_loss: 0.1456 - val_accuracy: 0.9396\n",
            "Epoch 317/500\n",
            "106/105 [==============================] - 22s 206ms/step - loss: 0.1847 - accuracy: 0.9227 - val_loss: 0.1448 - val_accuracy: 0.9392\n",
            "Epoch 318/500\n",
            "106/105 [==============================] - 22s 206ms/step - loss: 0.1775 - accuracy: 0.9292 - val_loss: 0.1434 - val_accuracy: 0.9407\n",
            "Epoch 319/500\n",
            "106/105 [==============================] - 22s 209ms/step - loss: 0.1780 - accuracy: 0.9269 - val_loss: 0.1456 - val_accuracy: 0.9392\n",
            "Epoch 320/500\n",
            "106/105 [==============================] - 22s 206ms/step - loss: 0.1850 - accuracy: 0.9263 - val_loss: 0.1448 - val_accuracy: 0.9400\n",
            "Epoch 321/500\n",
            "106/105 [==============================] - 22s 207ms/step - loss: 0.1781 - accuracy: 0.9298 - val_loss: 0.1481 - val_accuracy: 0.9384\n",
            "Epoch 322/500\n",
            "106/105 [==============================] - 22s 206ms/step - loss: 0.1857 - accuracy: 0.9266 - val_loss: 0.1446 - val_accuracy: 0.9388\n",
            "Epoch 323/500\n",
            "106/105 [==============================] - 22s 207ms/step - loss: 0.1805 - accuracy: 0.9279 - val_loss: 0.1497 - val_accuracy: 0.9381\n",
            "Epoch 324/500\n",
            "106/105 [==============================] - 22s 208ms/step - loss: 0.1820 - accuracy: 0.9277 - val_loss: 0.1442 - val_accuracy: 0.9392\n",
            "Epoch 325/500\n",
            "106/105 [==============================] - 22s 206ms/step - loss: 0.1751 - accuracy: 0.9302 - val_loss: 0.1455 - val_accuracy: 0.9381\n",
            "Epoch 326/500\n",
            "106/105 [==============================] - 22s 207ms/step - loss: 0.1785 - accuracy: 0.9289 - val_loss: 0.1458 - val_accuracy: 0.9392\n",
            "Epoch 327/500\n",
            "106/105 [==============================] - 22s 207ms/step - loss: 0.1816 - accuracy: 0.9272 - val_loss: 0.1452 - val_accuracy: 0.9403\n",
            "Epoch 328/500\n",
            "106/105 [==============================] - 22s 208ms/step - loss: 0.1825 - accuracy: 0.9247 - val_loss: 0.1469 - val_accuracy: 0.9396\n",
            "Epoch 329/500\n",
            "106/105 [==============================] - 22s 207ms/step - loss: 0.1839 - accuracy: 0.9242 - val_loss: 0.1469 - val_accuracy: 0.9377\n",
            "Epoch 330/500\n",
            "106/105 [==============================] - 22s 207ms/step - loss: 0.1893 - accuracy: 0.9236 - val_loss: 0.1451 - val_accuracy: 0.9392\n",
            "Epoch 331/500\n",
            "106/105 [==============================] - 22s 207ms/step - loss: 0.1715 - accuracy: 0.9303 - val_loss: 0.1429 - val_accuracy: 0.9407\n",
            "Epoch 332/500\n",
            "106/105 [==============================] - 22s 207ms/step - loss: 0.1855 - accuracy: 0.9263 - val_loss: 0.1463 - val_accuracy: 0.9400\n",
            "Epoch 333/500\n",
            "106/105 [==============================] - 22s 210ms/step - loss: 0.1872 - accuracy: 0.9268 - val_loss: 0.1451 - val_accuracy: 0.9403\n",
            "Epoch 334/500\n",
            "106/105 [==============================] - 22s 206ms/step - loss: 0.1789 - accuracy: 0.9256 - val_loss: 0.1477 - val_accuracy: 0.9381\n",
            "Epoch 335/500\n",
            "106/105 [==============================] - 22s 210ms/step - loss: 0.1848 - accuracy: 0.9280 - val_loss: 0.1442 - val_accuracy: 0.9396\n",
            "Epoch 336/500\n",
            "106/105 [==============================] - 23s 213ms/step - loss: 0.1801 - accuracy: 0.9267 - val_loss: 0.1459 - val_accuracy: 0.9381\n",
            "Epoch 337/500\n",
            "106/105 [==============================] - 22s 207ms/step - loss: 0.1837 - accuracy: 0.9269 - val_loss: 0.1460 - val_accuracy: 0.9384\n",
            "Epoch 338/500\n",
            "106/105 [==============================] - 22s 206ms/step - loss: 0.1781 - accuracy: 0.9277 - val_loss: 0.1453 - val_accuracy: 0.9384\n",
            "Epoch 339/500\n",
            "106/105 [==============================] - 22s 208ms/step - loss: 0.1842 - accuracy: 0.9271 - val_loss: 0.1450 - val_accuracy: 0.9396\n",
            "Epoch 340/500\n",
            "106/105 [==============================] - 22s 207ms/step - loss: 0.1813 - accuracy: 0.9270 - val_loss: 0.1473 - val_accuracy: 0.9411\n",
            "Epoch 341/500\n",
            "106/105 [==============================] - 22s 207ms/step - loss: 0.1842 - accuracy: 0.9244 - val_loss: 0.1425 - val_accuracy: 0.9411\n",
            "Epoch 342/500\n",
            "106/105 [==============================] - 22s 208ms/step - loss: 0.1779 - accuracy: 0.9286 - val_loss: 0.1445 - val_accuracy: 0.9396\n",
            "Epoch 343/500\n",
            "106/105 [==============================] - 22s 207ms/step - loss: 0.1766 - accuracy: 0.9305 - val_loss: 0.1455 - val_accuracy: 0.9400\n",
            "Epoch 344/500\n",
            "106/105 [==============================] - 22s 207ms/step - loss: 0.1780 - accuracy: 0.9288 - val_loss: 0.1436 - val_accuracy: 0.9418\n",
            "Epoch 345/500\n",
            "106/105 [==============================] - 22s 206ms/step - loss: 0.1784 - accuracy: 0.9279 - val_loss: 0.1444 - val_accuracy: 0.9396\n",
            "Epoch 346/500\n",
            "106/105 [==============================] - 22s 208ms/step - loss: 0.1792 - accuracy: 0.9272 - val_loss: 0.1433 - val_accuracy: 0.9422\n",
            "Epoch 347/500\n",
            "106/105 [==============================] - 22s 211ms/step - loss: 0.1828 - accuracy: 0.9267 - val_loss: 0.1427 - val_accuracy: 0.9407\n",
            "Epoch 348/500\n",
            "106/105 [==============================] - 22s 207ms/step - loss: 0.1786 - accuracy: 0.9286 - val_loss: 0.1434 - val_accuracy: 0.9400\n",
            "Epoch 349/500\n",
            "106/105 [==============================] - 22s 207ms/step - loss: 0.1809 - accuracy: 0.9261 - val_loss: 0.1449 - val_accuracy: 0.9400\n",
            "Epoch 350/500\n",
            "106/105 [==============================] - 22s 209ms/step - loss: 0.1835 - accuracy: 0.9249 - val_loss: 0.1461 - val_accuracy: 0.9396\n",
            "Epoch 351/500\n",
            "106/105 [==============================] - 22s 207ms/step - loss: 0.1881 - accuracy: 0.9246 - val_loss: 0.1450 - val_accuracy: 0.9388\n",
            "Epoch 352/500\n",
            "106/105 [==============================] - 22s 206ms/step - loss: 0.1780 - accuracy: 0.9277 - val_loss: 0.1451 - val_accuracy: 0.9388\n",
            "Epoch 353/500\n",
            "106/105 [==============================] - 22s 208ms/step - loss: 0.1779 - accuracy: 0.9263 - val_loss: 0.1445 - val_accuracy: 0.9400\n",
            "Epoch 354/500\n",
            "106/105 [==============================] - 22s 207ms/step - loss: 0.1795 - accuracy: 0.9259 - val_loss: 0.1454 - val_accuracy: 0.9384\n",
            "Epoch 355/500\n",
            "106/105 [==============================] - 22s 206ms/step - loss: 0.1846 - accuracy: 0.9242 - val_loss: 0.1444 - val_accuracy: 0.9396\n",
            "Epoch 356/500\n",
            "106/105 [==============================] - 22s 207ms/step - loss: 0.1818 - accuracy: 0.9272 - val_loss: 0.1440 - val_accuracy: 0.9403\n",
            "Epoch 357/500\n",
            "106/105 [==============================] - 22s 209ms/step - loss: 0.1887 - accuracy: 0.9231 - val_loss: 0.1448 - val_accuracy: 0.9392\n",
            "Epoch 358/500\n",
            "106/105 [==============================] - 22s 208ms/step - loss: 0.1843 - accuracy: 0.9283 - val_loss: 0.1427 - val_accuracy: 0.9407\n",
            "Epoch 359/500\n",
            "106/105 [==============================] - 22s 208ms/step - loss: 0.1794 - accuracy: 0.9286 - val_loss: 0.1436 - val_accuracy: 0.9407\n",
            "Epoch 360/500\n",
            "106/105 [==============================] - 22s 208ms/step - loss: 0.1802 - accuracy: 0.9255 - val_loss: 0.1428 - val_accuracy: 0.9388\n",
            "Epoch 361/500\n",
            "106/105 [==============================] - 22s 211ms/step - loss: 0.1792 - accuracy: 0.9283 - val_loss: 0.1455 - val_accuracy: 0.9381\n",
            "Epoch 362/500\n",
            "106/105 [==============================] - 22s 207ms/step - loss: 0.1800 - accuracy: 0.9284 - val_loss: 0.1610 - val_accuracy: 0.9369\n",
            "Epoch 363/500\n",
            "106/105 [==============================] - 22s 208ms/step - loss: 0.1819 - accuracy: 0.9242 - val_loss: 0.1464 - val_accuracy: 0.9388\n",
            "Epoch 364/500\n",
            "106/105 [==============================] - 22s 210ms/step - loss: 0.1823 - accuracy: 0.9265 - val_loss: 0.1437 - val_accuracy: 0.9388\n",
            "Epoch 365/500\n",
            "106/105 [==============================] - 22s 208ms/step - loss: 0.1808 - accuracy: 0.9275 - val_loss: 0.1446 - val_accuracy: 0.9384\n",
            "Epoch 366/500\n",
            "106/105 [==============================] - 22s 209ms/step - loss: 0.1790 - accuracy: 0.9259 - val_loss: 0.1432 - val_accuracy: 0.9388\n",
            "Epoch 367/500\n",
            "106/105 [==============================] - 22s 208ms/step - loss: 0.1770 - accuracy: 0.9298 - val_loss: 0.1452 - val_accuracy: 0.9384\n",
            "Epoch 368/500\n",
            "106/105 [==============================] - 22s 209ms/step - loss: 0.1791 - accuracy: 0.9240 - val_loss: 0.1485 - val_accuracy: 0.9381\n",
            "Epoch 369/500\n",
            "106/105 [==============================] - 22s 207ms/step - loss: 0.1823 - accuracy: 0.9277 - val_loss: 0.1440 - val_accuracy: 0.9384\n",
            "Epoch 370/500\n",
            "106/105 [==============================] - 22s 209ms/step - loss: 0.1785 - accuracy: 0.9276 - val_loss: 0.1434 - val_accuracy: 0.9392\n",
            "Epoch 371/500\n",
            "106/105 [==============================] - 22s 208ms/step - loss: 0.1832 - accuracy: 0.9263 - val_loss: 0.1464 - val_accuracy: 0.9381\n",
            "Epoch 372/500\n",
            "106/105 [==============================] - 22s 209ms/step - loss: 0.1794 - accuracy: 0.9291 - val_loss: 0.1440 - val_accuracy: 0.9384\n",
            "Epoch 373/500\n",
            "106/105 [==============================] - 22s 207ms/step - loss: 0.1816 - accuracy: 0.9258 - val_loss: 0.1430 - val_accuracy: 0.9396\n",
            "Epoch 374/500\n",
            "106/105 [==============================] - 22s 206ms/step - loss: 0.1808 - accuracy: 0.9274 - val_loss: 0.1464 - val_accuracy: 0.9369\n",
            "Epoch 375/500\n",
            "106/105 [==============================] - 22s 212ms/step - loss: 0.1796 - accuracy: 0.9279 - val_loss: 0.1430 - val_accuracy: 0.9403\n",
            "Epoch 376/500\n",
            "106/105 [==============================] - 22s 207ms/step - loss: 0.1781 - accuracy: 0.9291 - val_loss: 0.1415 - val_accuracy: 0.9411\n",
            "Epoch 377/500\n",
            "106/105 [==============================] - 22s 208ms/step - loss: 0.1765 - accuracy: 0.9297 - val_loss: 0.1430 - val_accuracy: 0.9400\n",
            "Epoch 378/500\n",
            "106/105 [==============================] - 22s 208ms/step - loss: 0.1785 - accuracy: 0.9292 - val_loss: 0.1442 - val_accuracy: 0.9377\n",
            "Epoch 379/500\n",
            "106/105 [==============================] - 22s 210ms/step - loss: 0.1791 - accuracy: 0.9313 - val_loss: 0.1457 - val_accuracy: 0.9396\n",
            "Epoch 380/500\n",
            "106/105 [==============================] - 22s 207ms/step - loss: 0.1779 - accuracy: 0.9301 - val_loss: 0.1431 - val_accuracy: 0.9392\n",
            "Epoch 381/500\n",
            "106/105 [==============================] - 22s 208ms/step - loss: 0.1840 - accuracy: 0.9239 - val_loss: 0.1450 - val_accuracy: 0.9384\n",
            "Epoch 382/500\n",
            "106/105 [==============================] - 22s 208ms/step - loss: 0.1766 - accuracy: 0.9303 - val_loss: 0.1444 - val_accuracy: 0.9381\n",
            "Epoch 383/500\n",
            "106/105 [==============================] - 22s 209ms/step - loss: 0.1836 - accuracy: 0.9240 - val_loss: 0.1426 - val_accuracy: 0.9392\n",
            "Epoch 384/500\n",
            "106/105 [==============================] - 22s 208ms/step - loss: 0.1834 - accuracy: 0.9263 - val_loss: 0.1488 - val_accuracy: 0.9377\n",
            "Epoch 385/500\n",
            "106/105 [==============================] - 22s 208ms/step - loss: 0.1770 - accuracy: 0.9289 - val_loss: 0.1453 - val_accuracy: 0.9388\n",
            "Epoch 386/500\n",
            "106/105 [==============================] - 22s 210ms/step - loss: 0.1815 - accuracy: 0.9272 - val_loss: 0.1471 - val_accuracy: 0.9392\n",
            "Epoch 387/500\n",
            "106/105 [==============================] - 22s 209ms/step - loss: 0.1851 - accuracy: 0.9251 - val_loss: 0.1490 - val_accuracy: 0.9415\n",
            "Epoch 388/500\n",
            "106/105 [==============================] - 22s 209ms/step - loss: 0.1819 - accuracy: 0.9242 - val_loss: 0.1445 - val_accuracy: 0.9403\n",
            "Epoch 389/500\n",
            "106/105 [==============================] - 22s 212ms/step - loss: 0.1835 - accuracy: 0.9266 - val_loss: 0.1427 - val_accuracy: 0.9400\n",
            "Epoch 390/500\n",
            "106/105 [==============================] - 22s 210ms/step - loss: 0.1783 - accuracy: 0.9283 - val_loss: 0.1456 - val_accuracy: 0.9392\n",
            "Epoch 391/500\n",
            "106/105 [==============================] - 22s 210ms/step - loss: 0.1808 - accuracy: 0.9268 - val_loss: 0.1445 - val_accuracy: 0.9388\n",
            "Epoch 392/500\n",
            "106/105 [==============================] - 22s 208ms/step - loss: 0.1742 - accuracy: 0.9291 - val_loss: 0.1435 - val_accuracy: 0.9388\n",
            "Epoch 393/500\n",
            "106/105 [==============================] - 22s 210ms/step - loss: 0.1779 - accuracy: 0.9296 - val_loss: 0.1478 - val_accuracy: 0.9400\n",
            "Epoch 394/500\n",
            "106/105 [==============================] - 22s 210ms/step - loss: 0.1806 - accuracy: 0.9268 - val_loss: 0.1430 - val_accuracy: 0.9407\n",
            "Epoch 395/500\n",
            "106/105 [==============================] - 22s 208ms/step - loss: 0.1750 - accuracy: 0.9288 - val_loss: 0.1419 - val_accuracy: 0.9407\n",
            "Epoch 396/500\n",
            "106/105 [==============================] - 22s 208ms/step - loss: 0.1768 - accuracy: 0.9290 - val_loss: 0.1458 - val_accuracy: 0.9392\n",
            "Epoch 397/500\n",
            "106/105 [==============================] - 22s 211ms/step - loss: 0.1846 - accuracy: 0.9271 - val_loss: 0.1466 - val_accuracy: 0.9403\n",
            "Epoch 398/500\n",
            "106/105 [==============================] - 22s 208ms/step - loss: 0.1817 - accuracy: 0.9275 - val_loss: 0.1468 - val_accuracy: 0.9392\n",
            "Epoch 399/500\n",
            "106/105 [==============================] - 22s 211ms/step - loss: 0.1894 - accuracy: 0.9227 - val_loss: 0.1451 - val_accuracy: 0.9392\n",
            "Epoch 400/500\n",
            "106/105 [==============================] - 23s 214ms/step - loss: 0.1791 - accuracy: 0.9282 - val_loss: 0.1402 - val_accuracy: 0.9400\n",
            "Epoch 401/500\n",
            "106/105 [==============================] - 22s 211ms/step - loss: 0.1814 - accuracy: 0.9275 - val_loss: 0.1443 - val_accuracy: 0.9400\n",
            "Epoch 402/500\n",
            "106/105 [==============================] - 22s 210ms/step - loss: 0.1802 - accuracy: 0.9278 - val_loss: 0.1440 - val_accuracy: 0.9403\n",
            "Epoch 403/500\n",
            "106/105 [==============================] - 22s 211ms/step - loss: 0.1772 - accuracy: 0.9256 - val_loss: 0.1467 - val_accuracy: 0.9373\n",
            "Epoch 404/500\n",
            "106/105 [==============================] - 22s 210ms/step - loss: 0.1822 - accuracy: 0.9256 - val_loss: 0.1418 - val_accuracy: 0.9418\n",
            "Epoch 405/500\n",
            "106/105 [==============================] - 22s 208ms/step - loss: 0.1860 - accuracy: 0.9265 - val_loss: 0.1431 - val_accuracy: 0.9377\n",
            "Epoch 406/500\n",
            "106/105 [==============================] - 22s 208ms/step - loss: 0.1773 - accuracy: 0.9301 - val_loss: 0.1432 - val_accuracy: 0.9422\n",
            "Epoch 407/500\n",
            "106/105 [==============================] - 22s 209ms/step - loss: 0.1792 - accuracy: 0.9270 - val_loss: 0.1416 - val_accuracy: 0.9403\n",
            "Epoch 408/500\n",
            "106/105 [==============================] - 22s 211ms/step - loss: 0.1785 - accuracy: 0.9262 - val_loss: 0.1420 - val_accuracy: 0.9396\n",
            "Epoch 409/500\n",
            "106/105 [==============================] - 22s 206ms/step - loss: 0.1800 - accuracy: 0.9282 - val_loss: 0.1412 - val_accuracy: 0.9411\n",
            "Epoch 410/500\n",
            "106/105 [==============================] - 22s 207ms/step - loss: 0.1851 - accuracy: 0.9231 - val_loss: 0.1430 - val_accuracy: 0.9400\n",
            "Epoch 411/500\n",
            "106/105 [==============================] - 22s 206ms/step - loss: 0.1776 - accuracy: 0.9286 - val_loss: 0.1442 - val_accuracy: 0.9396\n",
            "Epoch 412/500\n",
            "106/105 [==============================] - 22s 208ms/step - loss: 0.1762 - accuracy: 0.9279 - val_loss: 0.1468 - val_accuracy: 0.9384\n",
            "Epoch 413/500\n",
            "106/105 [==============================] - 22s 206ms/step - loss: 0.1832 - accuracy: 0.9273 - val_loss: 0.1420 - val_accuracy: 0.9418\n",
            "Epoch 414/500\n",
            "106/105 [==============================] - 22s 206ms/step - loss: 0.1790 - accuracy: 0.9285 - val_loss: 0.1411 - val_accuracy: 0.9426\n",
            "Epoch 415/500\n",
            "106/105 [==============================] - 22s 208ms/step - loss: 0.1767 - accuracy: 0.9301 - val_loss: 0.1426 - val_accuracy: 0.9418\n",
            "Epoch 416/500\n",
            "106/105 [==============================] - 22s 207ms/step - loss: 0.1778 - accuracy: 0.9268 - val_loss: 0.1431 - val_accuracy: 0.9396\n",
            "Epoch 417/500\n",
            "106/105 [==============================] - 22s 209ms/step - loss: 0.1833 - accuracy: 0.9291 - val_loss: 0.1434 - val_accuracy: 0.9396\n",
            "Epoch 418/500\n",
            "106/105 [==============================] - 22s 208ms/step - loss: 0.1759 - accuracy: 0.9295 - val_loss: 0.1426 - val_accuracy: 0.9415\n",
            "Epoch 419/500\n",
            "106/105 [==============================] - 22s 208ms/step - loss: 0.1731 - accuracy: 0.9292 - val_loss: 0.1404 - val_accuracy: 0.9407\n",
            "Epoch 420/500\n",
            "106/105 [==============================] - 22s 206ms/step - loss: 0.1734 - accuracy: 0.9298 - val_loss: 0.1424 - val_accuracy: 0.9403\n",
            "Epoch 421/500\n",
            "106/105 [==============================] - 22s 207ms/step - loss: 0.1754 - accuracy: 0.9301 - val_loss: 0.1410 - val_accuracy: 0.9407\n",
            "Epoch 422/500\n",
            "106/105 [==============================] - 22s 208ms/step - loss: 0.1751 - accuracy: 0.9308 - val_loss: 0.1428 - val_accuracy: 0.9415\n",
            "Epoch 423/500\n",
            "106/105 [==============================] - 22s 209ms/step - loss: 0.1907 - accuracy: 0.9223 - val_loss: 0.1427 - val_accuracy: 0.9418\n",
            "Epoch 424/500\n",
            "106/105 [==============================] - 23s 218ms/step - loss: 0.1755 - accuracy: 0.9305 - val_loss: 0.1454 - val_accuracy: 0.9381\n",
            "Epoch 425/500\n",
            "106/105 [==============================] - 24s 223ms/step - loss: 0.1769 - accuracy: 0.9289 - val_loss: 0.1439 - val_accuracy: 0.9403\n",
            "Epoch 426/500\n",
            "106/105 [==============================] - 23s 221ms/step - loss: 0.1866 - accuracy: 0.9260 - val_loss: 0.1404 - val_accuracy: 0.9434\n",
            "Epoch 427/500\n",
            "106/105 [==============================] - 23s 216ms/step - loss: 0.1808 - accuracy: 0.9292 - val_loss: 0.1395 - val_accuracy: 0.9422\n",
            "Epoch 428/500\n",
            "106/105 [==============================] - 23s 219ms/step - loss: 0.1823 - accuracy: 0.9282 - val_loss: 0.1406 - val_accuracy: 0.9418\n",
            "Epoch 429/500\n",
            "106/105 [==============================] - 24s 223ms/step - loss: 0.1778 - accuracy: 0.9265 - val_loss: 0.1392 - val_accuracy: 0.9411\n",
            "Epoch 430/500\n",
            "106/105 [==============================] - 23s 214ms/step - loss: 0.1744 - accuracy: 0.9300 - val_loss: 0.1432 - val_accuracy: 0.9407\n",
            "Epoch 431/500\n",
            "106/105 [==============================] - 23s 216ms/step - loss: 0.1779 - accuracy: 0.9291 - val_loss: 0.1462 - val_accuracy: 0.9388\n",
            "Epoch 432/500\n",
            "106/105 [==============================] - 23s 214ms/step - loss: 0.1757 - accuracy: 0.9303 - val_loss: 0.1413 - val_accuracy: 0.9418\n",
            "Epoch 433/500\n",
            "106/105 [==============================] - 23s 215ms/step - loss: 0.1739 - accuracy: 0.9282 - val_loss: 0.1441 - val_accuracy: 0.9384\n",
            "Epoch 434/500\n",
            "106/105 [==============================] - 23s 215ms/step - loss: 0.1772 - accuracy: 0.9284 - val_loss: 0.1428 - val_accuracy: 0.9396\n",
            "Epoch 435/500\n",
            "106/105 [==============================] - 23s 214ms/step - loss: 0.1770 - accuracy: 0.9290 - val_loss: 0.1423 - val_accuracy: 0.9396\n",
            "Epoch 436/500\n",
            "106/105 [==============================] - 23s 214ms/step - loss: 0.1847 - accuracy: 0.9274 - val_loss: 0.1439 - val_accuracy: 0.9396\n",
            "Epoch 437/500\n",
            "106/105 [==============================] - 23s 215ms/step - loss: 0.1734 - accuracy: 0.9274 - val_loss: 0.1417 - val_accuracy: 0.9415\n",
            "Epoch 438/500\n",
            "106/105 [==============================] - 23s 215ms/step - loss: 0.1849 - accuracy: 0.9276 - val_loss: 0.1410 - val_accuracy: 0.9407\n",
            "Epoch 439/500\n",
            "106/105 [==============================] - 23s 213ms/step - loss: 0.1771 - accuracy: 0.9267 - val_loss: 0.1411 - val_accuracy: 0.9411\n",
            "Epoch 440/500\n",
            "106/105 [==============================] - 23s 213ms/step - loss: 0.1788 - accuracy: 0.9305 - val_loss: 0.1476 - val_accuracy: 0.9396\n",
            "Epoch 441/500\n",
            "106/105 [==============================] - 23s 213ms/step - loss: 0.1816 - accuracy: 0.9268 - val_loss: 0.1418 - val_accuracy: 0.9400\n",
            "Epoch 442/500\n",
            "106/105 [==============================] - 23s 214ms/step - loss: 0.1759 - accuracy: 0.9276 - val_loss: 0.1436 - val_accuracy: 0.9392\n",
            "Epoch 443/500\n",
            "106/105 [==============================] - 23s 214ms/step - loss: 0.1780 - accuracy: 0.9290 - val_loss: 0.1467 - val_accuracy: 0.9392\n",
            "Epoch 444/500\n",
            "106/105 [==============================] - 23s 216ms/step - loss: 0.1865 - accuracy: 0.9224 - val_loss: 0.1408 - val_accuracy: 0.9411\n",
            "Epoch 445/500\n",
            "106/105 [==============================] - 23s 215ms/step - loss: 0.1757 - accuracy: 0.9286 - val_loss: 0.1427 - val_accuracy: 0.9400\n",
            "Epoch 446/500\n",
            "106/105 [==============================] - 23s 213ms/step - loss: 0.1732 - accuracy: 0.9296 - val_loss: 0.1429 - val_accuracy: 0.9407\n",
            "Epoch 447/500\n",
            "106/105 [==============================] - 23s 215ms/step - loss: 0.1751 - accuracy: 0.9310 - val_loss: 0.1438 - val_accuracy: 0.9400\n",
            "Epoch 448/500\n",
            "106/105 [==============================] - 23s 214ms/step - loss: 0.1753 - accuracy: 0.9305 - val_loss: 0.1448 - val_accuracy: 0.9384\n",
            "Epoch 449/500\n",
            "106/105 [==============================] - 23s 214ms/step - loss: 0.1771 - accuracy: 0.9282 - val_loss: 0.1487 - val_accuracy: 0.9388\n",
            "Epoch 450/500\n",
            "106/105 [==============================] - 23s 215ms/step - loss: 0.1719 - accuracy: 0.9319 - val_loss: 0.1396 - val_accuracy: 0.9437\n",
            "Epoch 451/500\n",
            "106/105 [==============================] - 23s 214ms/step - loss: 0.1793 - accuracy: 0.9278 - val_loss: 0.1430 - val_accuracy: 0.9407\n",
            "Epoch 452/500\n",
            "106/105 [==============================] - 23s 214ms/step - loss: 0.1798 - accuracy: 0.9284 - val_loss: 0.1420 - val_accuracy: 0.9384\n",
            "Epoch 453/500\n",
            "106/105 [==============================] - 23s 215ms/step - loss: 0.1742 - accuracy: 0.9321 - val_loss: 0.1407 - val_accuracy: 0.9384\n",
            "Epoch 454/500\n",
            "106/105 [==============================] - 23s 215ms/step - loss: 0.1766 - accuracy: 0.9287 - val_loss: 0.1424 - val_accuracy: 0.9396\n",
            "Epoch 455/500\n",
            "106/105 [==============================] - 23s 217ms/step - loss: 0.1743 - accuracy: 0.9313 - val_loss: 0.1435 - val_accuracy: 0.9392\n",
            "Epoch 456/500\n",
            "106/105 [==============================] - 23s 214ms/step - loss: 0.1772 - accuracy: 0.9297 - val_loss: 0.1393 - val_accuracy: 0.9418\n",
            "Epoch 457/500\n",
            "106/105 [==============================] - 23s 214ms/step - loss: 0.1779 - accuracy: 0.9305 - val_loss: 0.1426 - val_accuracy: 0.9388\n",
            "Epoch 458/500\n",
            "106/105 [==============================] - 23s 219ms/step - loss: 0.1711 - accuracy: 0.9289 - val_loss: 0.1402 - val_accuracy: 0.9411\n",
            "Epoch 459/500\n",
            "106/105 [==============================] - 22s 212ms/step - loss: 0.1746 - accuracy: 0.9313 - val_loss: 0.1376 - val_accuracy: 0.9452\n",
            "Epoch 460/500\n",
            "106/105 [==============================] - 22s 208ms/step - loss: 0.1808 - accuracy: 0.9274 - val_loss: 0.1503 - val_accuracy: 0.9392\n",
            "Epoch 461/500\n",
            "106/105 [==============================] - 22s 210ms/step - loss: 0.1743 - accuracy: 0.9294 - val_loss: 0.1417 - val_accuracy: 0.9426\n",
            "Epoch 462/500\n",
            "106/105 [==============================] - 22s 208ms/step - loss: 0.1786 - accuracy: 0.9260 - val_loss: 0.1397 - val_accuracy: 0.9437\n",
            "Epoch 463/500\n",
            "106/105 [==============================] - 22s 210ms/step - loss: 0.1796 - accuracy: 0.9277 - val_loss: 0.1404 - val_accuracy: 0.9430\n",
            "Epoch 464/500\n",
            "106/105 [==============================] - 22s 208ms/step - loss: 0.1805 - accuracy: 0.9280 - val_loss: 0.1449 - val_accuracy: 0.9415\n",
            "Epoch 465/500\n",
            "106/105 [==============================] - 22s 210ms/step - loss: 0.1764 - accuracy: 0.9292 - val_loss: 0.1494 - val_accuracy: 0.9369\n",
            "Epoch 466/500\n",
            "106/105 [==============================] - 22s 210ms/step - loss: 0.1781 - accuracy: 0.9265 - val_loss: 0.1444 - val_accuracy: 0.9396\n",
            "Epoch 467/500\n",
            "106/105 [==============================] - 22s 209ms/step - loss: 0.1785 - accuracy: 0.9264 - val_loss: 0.1456 - val_accuracy: 0.9396\n",
            "Epoch 468/500\n",
            "106/105 [==============================] - 22s 210ms/step - loss: 0.1720 - accuracy: 0.9297 - val_loss: 0.1410 - val_accuracy: 0.9403\n",
            "Epoch 469/500\n",
            "106/105 [==============================] - 22s 211ms/step - loss: 0.1776 - accuracy: 0.9295 - val_loss: 0.1414 - val_accuracy: 0.9407\n",
            "Epoch 470/500\n",
            "106/105 [==============================] - 22s 211ms/step - loss: 0.1756 - accuracy: 0.9299 - val_loss: 0.1491 - val_accuracy: 0.9407\n",
            "Epoch 471/500\n",
            "106/105 [==============================] - 22s 209ms/step - loss: 0.1793 - accuracy: 0.9287 - val_loss: 0.1385 - val_accuracy: 0.9434\n",
            "Epoch 472/500\n",
            "106/105 [==============================] - 22s 212ms/step - loss: 0.1790 - accuracy: 0.9276 - val_loss: 0.1403 - val_accuracy: 0.9434\n",
            "Epoch 473/500\n",
            "106/105 [==============================] - 22s 210ms/step - loss: 0.1740 - accuracy: 0.9301 - val_loss: 0.1410 - val_accuracy: 0.9437\n",
            "Epoch 474/500\n",
            "106/105 [==============================] - 22s 209ms/step - loss: 0.1843 - accuracy: 0.9260 - val_loss: 0.1410 - val_accuracy: 0.9418\n",
            "Epoch 475/500\n",
            "106/105 [==============================] - 22s 209ms/step - loss: 0.1777 - accuracy: 0.9276 - val_loss: 0.1413 - val_accuracy: 0.9407\n",
            "Epoch 476/500\n",
            "106/105 [==============================] - 23s 213ms/step - loss: 0.1765 - accuracy: 0.9308 - val_loss: 0.1417 - val_accuracy: 0.9434\n",
            "Epoch 477/500\n",
            "106/105 [==============================] - 22s 211ms/step - loss: 0.1766 - accuracy: 0.9301 - val_loss: 0.1441 - val_accuracy: 0.9411\n",
            "Epoch 478/500\n",
            "106/105 [==============================] - 22s 210ms/step - loss: 0.1764 - accuracy: 0.9294 - val_loss: 0.1405 - val_accuracy: 0.9418\n",
            "Epoch 479/500\n",
            "106/105 [==============================] - 22s 210ms/step - loss: 0.1778 - accuracy: 0.9290 - val_loss: 0.1418 - val_accuracy: 0.9392\n",
            "Epoch 480/500\n",
            "106/105 [==============================] - 22s 211ms/step - loss: 0.1808 - accuracy: 0.9275 - val_loss: 0.1450 - val_accuracy: 0.9388\n",
            "Epoch 481/500\n",
            "106/105 [==============================] - 22s 209ms/step - loss: 0.1738 - accuracy: 0.9279 - val_loss: 0.1422 - val_accuracy: 0.9388\n",
            "Epoch 482/500\n",
            "106/105 [==============================] - 22s 209ms/step - loss: 0.1760 - accuracy: 0.9293 - val_loss: 0.1455 - val_accuracy: 0.9403\n",
            "Epoch 483/500\n",
            "106/105 [==============================] - 22s 209ms/step - loss: 0.1809 - accuracy: 0.9281 - val_loss: 0.1421 - val_accuracy: 0.9400\n",
            "Epoch 484/500\n",
            "106/105 [==============================] - 22s 211ms/step - loss: 0.1810 - accuracy: 0.9297 - val_loss: 0.1400 - val_accuracy: 0.9415\n",
            "Epoch 485/500\n",
            "106/105 [==============================] - 22s 210ms/step - loss: 0.1825 - accuracy: 0.9271 - val_loss: 0.1402 - val_accuracy: 0.9403\n",
            "Epoch 486/500\n",
            "106/105 [==============================] - 22s 212ms/step - loss: 0.1771 - accuracy: 0.9262 - val_loss: 0.1423 - val_accuracy: 0.9415\n",
            "Epoch 487/500\n",
            "106/105 [==============================] - 22s 210ms/step - loss: 0.1754 - accuracy: 0.9297 - val_loss: 0.1400 - val_accuracy: 0.9430\n",
            "Epoch 488/500\n",
            "106/105 [==============================] - 22s 210ms/step - loss: 0.1772 - accuracy: 0.9277 - val_loss: 0.1438 - val_accuracy: 0.9418\n",
            "Epoch 489/500\n",
            "106/105 [==============================] - 22s 209ms/step - loss: 0.1775 - accuracy: 0.9276 - val_loss: 0.1440 - val_accuracy: 0.9396\n",
            "Epoch 490/500\n",
            "106/105 [==============================] - 22s 212ms/step - loss: 0.1777 - accuracy: 0.9300 - val_loss: 0.1487 - val_accuracy: 0.9396\n",
            "Epoch 491/500\n",
            "106/105 [==============================] - 22s 209ms/step - loss: 0.1779 - accuracy: 0.9279 - val_loss: 0.1436 - val_accuracy: 0.9411\n",
            "Epoch 492/500\n",
            "106/105 [==============================] - 22s 209ms/step - loss: 0.1775 - accuracy: 0.9306 - val_loss: 0.1426 - val_accuracy: 0.9392\n",
            "Epoch 493/500\n",
            "106/105 [==============================] - 22s 210ms/step - loss: 0.1788 - accuracy: 0.9271 - val_loss: 0.1405 - val_accuracy: 0.9434\n",
            "Epoch 494/500\n",
            "106/105 [==============================] - 22s 211ms/step - loss: 0.1795 - accuracy: 0.9279 - val_loss: 0.1402 - val_accuracy: 0.9418\n",
            "Epoch 495/500\n",
            "106/105 [==============================] - 22s 210ms/step - loss: 0.1754 - accuracy: 0.9276 - val_loss: 0.1406 - val_accuracy: 0.9418\n",
            "Epoch 496/500\n",
            "106/105 [==============================] - 22s 210ms/step - loss: 0.1730 - accuracy: 0.9284 - val_loss: 0.1434 - val_accuracy: 0.9415\n",
            "Epoch 497/500\n",
            "106/105 [==============================] - 23s 213ms/step - loss: 0.1757 - accuracy: 0.9305 - val_loss: 0.1437 - val_accuracy: 0.9392\n",
            "Epoch 498/500\n",
            "106/105 [==============================] - 22s 211ms/step - loss: 0.1761 - accuracy: 0.9301 - val_loss: 0.1412 - val_accuracy: 0.9430\n",
            "Epoch 499/500\n",
            "106/105 [==============================] - 22s 210ms/step - loss: 0.1794 - accuracy: 0.9259 - val_loss: 0.1435 - val_accuracy: 0.9400\n",
            "Epoch 500/500\n",
            "106/105 [==============================] - 23s 213ms/step - loss: 0.1715 - accuracy: 0.9308 - val_loss: 0.1499 - val_accuracy: 0.9381\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xwma97gSm4Gn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}